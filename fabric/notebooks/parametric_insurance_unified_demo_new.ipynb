{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d03c41-28e5-431d-b8e8-2589065f51d0",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Fabric notebook source\n",
    "# ============================================================================\n",
    "# PARAMETRIC INSURANCE DEMO â€” UNIFIED NOTEBOOK WITH EVENT GRID\n",
    "# Power Outage Business Interruption Insurance\n",
    "# ============================================================================\n",
    "# This single notebook runs the ENTIRE demo end-to-end in Microsoft Fabric\n",
    "# AND publishes events to Azure Event Grid at every pipeline stage:\n",
    "#\n",
    "#   Step 0: Configuration & Imports\n",
    "#   Step 1: Simulate Power Outages with PRESTO\n",
    "#   Step 2: Enrich with NOAA Weather Data (free API)\n",
    "#   Step 3: Match Outages to Policies â†’ publish \"outage.detected\"\n",
    "#   Step 4: Validate Claims via Foundry Agent â†’ publish \"claim.approved\" / \"claim.denied\"\n",
    "#   Step 5: Process Payouts â†’ publish \"payout.processed\"\n",
    "#   Step 6: Dashboard Summary + Event Audit Log\n",
    "#\n",
    "# Event Grid Integration:\n",
    "#   - 4 event types published across the pipeline\n",
    "#   - Events can trigger Azure Functions, Logic Apps, or Webhooks\n",
    "#   - Full event audit trail stored in Delta table\n",
    "#   - Graceful fallback when Event Grid is not configured\n",
    "#\n",
    "# Free Public Data Sources Used:\n",
    "#   - NOAA Weather API (https://api.weather.gov) â€” No API key required\n",
    "#   - PRESTO (local simulation) â€” No API key required\n",
    "# ============================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a525f967-70dd-4fd3-b7e9-e1fd6cf93052",
   "metadata": {},
   "source": [
    "# ðŸ—ï¸ Parametric Insurance Demo â€” Unified Notebook + Event Grid\n",
    "# MAGIC\n",
    "| Step | Description | Data Source | Event Grid |\n",
    "|------|-------------|------------|------------|\n",
    "| 1 | Simulate Outages | **PRESTO** (free) | â€” |\n",
    "| 2 | Weather Enrichment | **NOAA API** (free) | â€” |\n",
    "| 3 | Match â†’ Policies | Fabric SQL | `outage.detected` |\n",
    "| 4 | AI Claim Validation | **Foundry Agent** | `claim.approved` / `claim.denied` |\n",
    "| 5 | Process Payouts | Fabric SQL | `payout.processed` |\n",
    "| 6 | Summary + Audit | Analytics | â€” |\n",
    "# MAGIC\n",
    "> âš¡ `PRESTO â†’ Fabric â†’ Event Grid â†’ Foundry AI â†’ Event Grid â†’ Payout â†’ Event Grid`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056db181-f4f0-4f37-8c09-c696ccc9bafd",
   "metadata": {},
   "source": [
    "## ðŸ”§ Step 0 â€” Configuration & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dde00c-7ef8-4280-a21a-416e1ef6c650",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "%pip install azure-ai-projects==2.0.0b3 azure-core azure-ai-agents\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import uuid\n",
    "import math\n",
    "import random\n",
    "import requests\n",
    "import warnings\n",
    "import traceback\n",
    "import notebookutils\n",
    "from datetime import datetime, timedelta\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import (\n",
    "    StructType, StructField, StringType, IntegerType,\n",
    "    DoubleType, TimestampType, FloatType, BooleanType\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# CONFIGURATION â€” Edit these values for your environment\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "@dataclass\n",
    "class DemoConfig:\n",
    "    \"\"\"Centralized configuration for the entire demo.\"\"\"\n",
    "\n",
    "    # -- Fabric --\n",
    "    lakehouse_name: str = \"parametric_insurance_lakehouse\"\n",
    "    warehouse_name: str = \"parametric_insurance_warehouse\"\n",
    "\n",
    "    # -- PRESTO Simulation --\n",
    "    scenario_type: str = \"severe_weather\"   # normal_day | severe_weather | heat_wave | winter_storm\n",
    "    min_customer_impact: int = 500\n",
    "\n",
    "    # -- NOAA Weather API (free) --\n",
    "    noaa_api_url: str = \"https://api.weather.gov\"\n",
    "    noaa_user_agent: str = \"ParametricInsuranceDemo/1.0 (kalateef@microsoft.com)\"\n",
    "\n",
    "    # -- Foundry Agent (This uses agents created using the \"New Foundry\" experience) --\n",
    "    foundry_endpoint: str = \"<foundry-endpoint>\" # https://<resource>.services.ai.azure.com/api/projects/<project>\n",
    "    foundry_agent: str = \"<agent_id>\"\n",
    "\n",
    "    # -- Azure Event Grid (optional â€” leave blank for local-only mode) --\n",
    "    eventgrid_topic_endpoint: str = \"<eventgrid-endpoint>\"\n",
    "    eventgrid_topic_key: str = \"<eventgrid-key>\"\n",
    "\n",
    "    # -- Event types (match existing Azure Function subscriptions) --\n",
    "    EVT_OUTAGE_DETECTED: str = \"outage.detected\"\n",
    "    EVT_THRESHOLD_EXCEEDED: str = \"outage.threshold.exceeded\"\n",
    "    EVT_CLAIM_APPROVED: str = \"claim.approved\"\n",
    "    EVT_CLAIM_DENIED: str = \"claim.denied\"\n",
    "    EVT_PAYOUT_PROCESSED: str = \"payout.processed\"\n",
    "\n",
    "    # -- Policy Defaults --\n",
    "    default_threshold_minutes: int = 120\n",
    "    default_hourly_rate: float = 500.0\n",
    "    max_payout_per_claim: float = 50000.0\n",
    "\n",
    "\n",
    "config = DemoConfig()\n",
    "\n",
    "# Override from environment variables / notebook widgets\n",
    "config.foundry_endpoint        = os.getenv(\"FOUNDRY_ENDPOINT\", config.foundry_endpoint)\n",
    "config.eventgrid_topic_endpoint = os.getenv(\"EVENTGRID_TOPIC_ENDPOINT\", config.eventgrid_topic_endpoint)\n",
    "config.eventgrid_topic_key     = os.getenv(\"EVENTGRID_KEY\", config.eventgrid_topic_key)\n",
    "\n",
    "# Create a Variable Library (eg. \"environmentVariables\") in Fabric workspace to store these variables\n",
    "environment_library = notebookutils.variableLibrary.getLibrary(\"environmentVariables\")\n",
    "\n",
    "os.environ[\"AZURE_CLIENT_ID\"] = environment_library.AZURE_CLIENT_ID\n",
    "os.environ[\"AZURE_TENANT_ID\"] = environment_library.AZURE_TENANT_ID\n",
    "os.environ[\"AZURE_CLIENT_SECRET\"] = environment_library.AZURE_CLIENT_SECRET\n",
    "\n",
    "# Detect Fabric\n",
    "try:\n",
    "    from notebookutils import mssparkutils\n",
    "    FABRIC_ENV = True\n",
    "    print(\"âœ… Running inside Microsoft Fabric\")\n",
    "    # Try loading from notebook widgets (set via pipeline parameters)\n",
    "    try:\n",
    "        config.eventgrid_topic_endpoint = config.eventgrid_topic_endpoint or mssparkutils.widgets.get(\"eventgrid_endpoint\")\n",
    "        config.eventgrid_topic_key = config.eventgrid_topic_key or mssparkutils.widgets.get(\"eventgrid_key\")\n",
    "    except Exception:\n",
    "        pass\n",
    "except ImportError:\n",
    "    FABRIC_ENV = False\n",
    "    print(\"âš ï¸  Running outside Fabric â€” results saved locally\")\n",
    "\n",
    "EVENTGRID_ENABLED = bool(config.eventgrid_topic_endpoint and config.eventgrid_topic_key)\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "print(f\"ðŸ“‹ Scenario:          {config.scenario_type}\")\n",
    "print(f\"ðŸ“‹ Min Customer Impact: {config.min_customer_impact}\")\n",
    "print(f\"ðŸ“‹ Foundry Agent:     {'Enabled' if config.foundry_endpoint else 'Rule-based fallback'}\")\n",
    "print(f\"ðŸ“‹ Event Grid:        {'âœ… ENABLED' if EVENTGRID_ENABLED else 'âš ï¸  DISABLED (local-only mode)'}\")\n",
    "print(f\"ðŸ“‹ Timestamp:         {datetime.utcnow().isoformat()}Z\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9491bd84-fe45-452e-9f41-0df2baf488d9",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ“¡ Event Grid Client (embedded)\n",
    "# MAGIC\n",
    "Lightweight Event Grid publisher that works inside a Fabric notebook.\n",
    "Publishes CloudEvents-compatible messages to an Event Grid Topic.\n",
    "Falls back gracefully when Event Grid is not configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2aa47ae-7b92-4eeb-9aea-c1dc1443352f",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Event Grid Publisher â€” notebook-embedded, zero external dependencies\n",
    "# Uses the Event Grid REST API directly (no azure-eventgrid SDK required)\n",
    "# ============================================================================\n",
    "\n",
    "class NotebookEventGridClient:\n",
    "    \"\"\"\n",
    "    Lightweight Event Grid publisher for use inside Fabric notebooks.\n",
    "    Uses the Event Grid REST API with SAS key authentication.\n",
    "    Stores an audit log of all events locally in a list.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, endpoint: str, key: str):\n",
    "        self.endpoint = endpoint.rstrip(\"/\")\n",
    "        self.key = key\n",
    "        self.audit_log: List[Dict[str, Any]] = []\n",
    "        self._event_counter = 0\n",
    "\n",
    "    def publish_event(\n",
    "        self,\n",
    "        event_type: str,\n",
    "        subject: str,\n",
    "        data: Dict[str, Any],\n",
    "        data_version: str = \"1.0\",\n",
    "    ) -> bool:\n",
    "        \"\"\"\n",
    "        Publish a single EventGridEvent to the topic.\n",
    "        Returns True on success, False on failure (never raises).\n",
    "        \"\"\"\n",
    "        event_id = str(uuid.uuid4())\n",
    "        event_time = datetime.utcnow().isoformat() + \"Z\"\n",
    "        self._event_counter += 1\n",
    "\n",
    "        event_payload = [\n",
    "            {\n",
    "                \"id\": event_id,\n",
    "                \"eventType\": event_type,\n",
    "                \"subject\": subject,\n",
    "                \"eventTime\": event_time,\n",
    "                \"data\": data,\n",
    "                \"dataVersion\": data_version,\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        # Audit record (always stored, even if publish fails)\n",
    "        audit = {\n",
    "            \"sequence\": self._event_counter,\n",
    "            \"event_id\": event_id,\n",
    "            \"event_type\": event_type,\n",
    "            \"subject\": subject,\n",
    "            \"event_time\": event_time,\n",
    "            \"data_summary\": json.dumps(data, default=str)[:500],\n",
    "            \"status\": \"pending\",\n",
    "            \"error\": None,\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            resp = requests.post(\n",
    "                f\"{self.endpoint}/api/events?api-version=2018-01-01\",\n",
    "                headers={\n",
    "                    \"Content-Type\": \"application/json\",\n",
    "                    \"aeg-sas-key\": self.key,\n",
    "                },\n",
    "                json=event_payload,\n",
    "                timeout=15,\n",
    "            )\n",
    "            resp.raise_for_status()\n",
    "            audit[\"status\"] = \"published\"\n",
    "            self.audit_log.append(audit)\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            audit[\"status\"] = \"failed\"\n",
    "            audit[\"error\"] = str(e)\n",
    "            self.audit_log.append(audit)\n",
    "            print(f\"  âš ï¸  Event Grid publish failed for {event_type}: {e}\")\n",
    "            return False\n",
    "\n",
    "    def publish_batch(self, events: List[Dict[str, Any]]) -> bool:\n",
    "        \"\"\"Publish multiple events in a single batch.\"\"\"\n",
    "        batch = []\n",
    "        audits = []\n",
    "        for evt in events:\n",
    "            eid = str(uuid.uuid4())\n",
    "            etime = datetime.utcnow().isoformat() + \"Z\"\n",
    "            self._event_counter += 1\n",
    "            batch.append({\n",
    "                \"id\": eid,\n",
    "                \"eventType\": evt[\"event_type\"],\n",
    "                \"subject\": evt[\"subject\"],\n",
    "                \"eventTime\": etime,\n",
    "                \"data\": evt[\"data\"],\n",
    "                \"dataVersion\": evt.get(\"data_version\", \"1.0\"),\n",
    "            })\n",
    "            audits.append({\n",
    "                \"sequence\": self._event_counter,\n",
    "                \"event_id\": eid,\n",
    "                \"event_type\": evt[\"event_type\"],\n",
    "                \"subject\": evt[\"subject\"],\n",
    "                \"event_time\": etime,\n",
    "                \"data_summary\": json.dumps(evt[\"data\"], default=str)[:500],\n",
    "                \"status\": \"pending\",\n",
    "                \"error\": None,\n",
    "            })\n",
    "\n",
    "        try:\n",
    "            resp = requests.post(\n",
    "                f\"{self.endpoint}/api/events?api-version=2018-01-01\",\n",
    "                headers={\n",
    "                    \"Content-Type\": \"application/json\",\n",
    "                    \"aeg-sas-key\": self.key,\n",
    "                },\n",
    "                json=batch,\n",
    "                timeout=30,\n",
    "            )\n",
    "            resp.raise_for_status()\n",
    "            for a in audits:\n",
    "                a[\"status\"] = \"published\"\n",
    "            self.audit_log.extend(audits)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            for a in audits:\n",
    "                a[\"status\"] = \"failed\"\n",
    "                a[\"error\"] = str(e)\n",
    "            self.audit_log.extend(audits)\n",
    "            print(f\"  âš ï¸  Batch publish failed: {e}\")\n",
    "            return False\n",
    "\n",
    "\n",
    "# ---- Local-only stub when Event Grid is disabled ----\n",
    "class LocalEventLogger:\n",
    "    \"\"\"Drop-in replacement that logs events locally without publishing.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.audit_log: List[Dict[str, Any]] = []\n",
    "        self._event_counter = 0\n",
    "\n",
    "    def publish_event(self, event_type: str, subject: str, data: Dict[str, Any], **kw) -> bool:\n",
    "        self._event_counter += 1\n",
    "        self.audit_log.append({\n",
    "            \"sequence\": self._event_counter,\n",
    "            \"event_id\": str(uuid.uuid4()),\n",
    "            \"event_type\": event_type,\n",
    "            \"subject\": subject,\n",
    "            \"event_time\": datetime.utcnow().isoformat() + \"Z\",\n",
    "            \"data_summary\": json.dumps(data, default=str)[:500],\n",
    "            \"status\": \"local_only\",\n",
    "            \"error\": None,\n",
    "        })\n",
    "        return True\n",
    "\n",
    "    def publish_batch(self, events: List[Dict[str, Any]]) -> bool:\n",
    "        for evt in events:\n",
    "            self.publish_event(evt[\"event_type\"], evt[\"subject\"], evt[\"data\"])\n",
    "        return True\n",
    "\n",
    "\n",
    "# ---- Initialize ----\n",
    "if EVENTGRID_ENABLED:\n",
    "    eg_client = NotebookEventGridClient(config.eventgrid_topic_endpoint, config.eventgrid_topic_key)\n",
    "    print(\"ðŸ“¡ Event Grid client initialized â€” events will be published to Azure\")\n",
    "else:\n",
    "    eg_client = LocalEventLogger()\n",
    "    print(\"ðŸ“ Local event logger initialized â€” events recorded locally only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe52372-c1f4-46e6-b5c4-19169b171ce0",
   "metadata": {},
   "source": [
    "### 0b. Test Event Grid Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632600ae-9586-4edb-9bf2-826b40ab0272",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "if EVENTGRID_ENABLED:\n",
    "    print(\"ðŸ”Œ Testing Event Grid connection...\")\n",
    "    test_ok = eg_client.publish_event(\n",
    "        event_type=\"test.connection\",\n",
    "        subject=\"test/notebook-startup\",\n",
    "        data={\n",
    "            \"test\": True,\n",
    "            \"timestamp\": datetime.utcnow().isoformat(),\n",
    "            \"source\": \"parametric-insurance-notebook\",\n",
    "            \"message\": \"Connection test from Fabric notebook\",\n",
    "        },\n",
    "    )\n",
    "    if test_ok:\n",
    "        print(\"âœ… Event Grid connection verified â€” test event published successfully!\")\n",
    "    else:\n",
    "        print(\"âŒ Event Grid connection FAILED â€” check endpoint and key.\")\n",
    "        print(\"   Continuing in local-only mode.\")\n",
    "        eg_client = LocalEventLogger()\n",
    "        EVENTGRID_ENABLED = False\n",
    "else:\n",
    "    print(\"â„¹ï¸  Event Grid not configured â€” skipping connection test.\")\n",
    "    print(\"   Set EVENTGRID_TOPIC_ENDPOINT and EVENTGRID_KEY to enable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635e7595-1f59-4afd-9d8e-5b4c7be53f5d",
   "metadata": {},
   "source": [
    "---\n",
    "## âš¡ Step 1 â€” Simulate Power Outages with PRESTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030a3f26-d9c7-4c01-aa49-6d59323fe133",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "class PRESTO:\n",
    "    \"\"\"Power Reliability Event Simulation Tool â€” generates realistic outage scenarios.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.cities = [\n",
    "            {\"name\": \"Seattle\",       \"state\": \"WA\", \"zip\": \"98101\", \"lat\": 47.6062, \"lon\": -122.3321, \"region\": \"Pacific Northwest\"},\n",
    "            {\"name\": \"Portland\",      \"state\": \"OR\", \"zip\": \"97201\", \"lat\": 45.5152, \"lon\": -122.6784, \"region\": \"Pacific Northwest\"},\n",
    "            {\"name\": \"San Francisco\", \"state\": \"CA\", \"zip\": \"94102\", \"lat\": 37.7749, \"lon\": -122.4194, \"region\": \"California\"},\n",
    "            {\"name\": \"Los Angeles\",   \"state\": \"CA\", \"zip\": \"90012\", \"lat\": 34.0522, \"lon\": -118.2437, \"region\": \"California\"},\n",
    "            {\"name\": \"San Diego\",     \"state\": \"CA\", \"zip\": \"92101\", \"lat\": 32.7157, \"lon\": -117.1611, \"region\": \"California\"},\n",
    "            {\"name\": \"Phoenix\",       \"state\": \"AZ\", \"zip\": \"85001\", \"lat\": 33.4484, \"lon\": -112.0740, \"region\": \"Southwest\"},\n",
    "            {\"name\": \"Las Vegas\",     \"state\": \"NV\", \"zip\": \"89101\", \"lat\": 36.1699, \"lon\": -115.1398, \"region\": \"Southwest\"},\n",
    "            {\"name\": \"Denver\",        \"state\": \"CO\", \"zip\": \"80202\", \"lat\": 39.7392, \"lon\": -104.9903, \"region\": \"Mountain\"},\n",
    "            {\"name\": \"Chicago\",       \"state\": \"IL\", \"zip\": \"60601\", \"lat\": 41.8781, \"lon\": -87.6298, \"region\": \"Midwest\"},\n",
    "            {\"name\": \"Detroit\",       \"state\": \"MI\", \"zip\": \"48201\", \"lat\": 42.3314, \"lon\": -83.0458, \"region\": \"Midwest\"},\n",
    "            {\"name\": \"Atlanta\",       \"state\": \"GA\", \"zip\": \"30303\", \"lat\": 33.7490, \"lon\": -84.3880, \"region\": \"South\"},\n",
    "            {\"name\": \"Miami\",         \"state\": \"FL\", \"zip\": \"33101\", \"lat\": 25.7617, \"lon\": -80.1918, \"region\": \"South\"},\n",
    "            {\"name\": \"Houston\",       \"state\": \"TX\", \"zip\": \"77002\", \"lat\": 29.7604, \"lon\": -95.3698, \"region\": \"Texas\"},\n",
    "            {\"name\": \"Dallas\",        \"state\": \"TX\", \"zip\": \"75201\", \"lat\": 32.7767, \"lon\": -96.7970, \"region\": \"Texas\"},\n",
    "            {\"name\": \"Austin\",        \"state\": \"TX\", \"zip\": \"78701\", \"lat\": 30.2672, \"lon\": -97.7431, \"region\": \"Texas\"},\n",
    "            {\"name\": \"New York\",      \"state\": \"NY\", \"zip\": \"10001\", \"lat\": 40.7128, \"lon\": -74.0060, \"region\": \"Northeast\"},\n",
    "            {\"name\": \"Boston\",        \"state\": \"MA\", \"zip\": \"02101\", \"lat\": 42.3601, \"lon\": -71.0589, \"region\": \"Northeast\"},\n",
    "            {\"name\": \"Philadelphia\",  \"state\": \"PA\", \"zip\": \"19102\", \"lat\": 39.9526, \"lon\": -75.1652, \"region\": \"Mid-Atlantic\"},\n",
    "            {\"name\": \"Washington\",    \"state\": \"DC\", \"zip\": \"20001\", \"lat\": 38.9072, \"lon\": -77.0369, \"region\": \"Mid-Atlantic\"},\n",
    "        ]\n",
    "        self.utilities = {\n",
    "            \"Pacific Northwest\": [\"Seattle City Light\", \"Portland General Electric\", \"Puget Sound Energy\", \"Tacoma Power\"],\n",
    "            \"California\":        [\"Pacific Gas & Electric (PG&E)\", \"Southern California Edison\", \"San Diego Gas & Electric\", \"LADWP\"],\n",
    "            \"Southwest\":         [\"Arizona Public Service\", \"Salt River Project\", \"NV Energy\"],\n",
    "            \"Mountain\":          [\"Xcel Energy\", \"Black Hills Energy\", \"Rocky Mountain Power\"],\n",
    "            \"Midwest\":           [\"ComEd\", \"DTE Energy\", \"Duke Energy Ohio\", \"Consumers Energy\"],\n",
    "            \"South\":             [\"Georgia Power\", \"Duke Energy Carolinas\", \"Florida Power & Light\", \"Entergy\"],\n",
    "            \"Texas\":             [\"Oncor Electric Delivery\", \"CenterPoint Energy\", \"Austin Energy\", \"AEP Texas\"],\n",
    "            \"Northeast\":         [\"Con Edison\", \"National Grid\", \"Eversource Energy\", \"PSEG\"],\n",
    "            \"Mid-Atlantic\":      [\"PECO Energy\", \"Pepco\", \"BGE\", \"Dominion Energy\"],\n",
    "        }\n",
    "        self.outage_causes = [\n",
    "            (\"storm_damage\", 0.35), (\"equipment_failure\", 0.25), (\"tree_contact\", 0.15),\n",
    "            (\"vehicle_accident\", 0.08), (\"animal_contact\", 0.05), (\"overload\", 0.05),\n",
    "            (\"planned_maintenance\", 0.03), (\"lightning\", 0.02), (\"unknown\", 0.02),\n",
    "        ]\n",
    "\n",
    "    def _pick_cause(self, ws): \n",
    "        c, w = zip(*self.outage_causes); w = list(w)\n",
    "        if ws in (\"severe\",\"extreme\"): w[0]*=3; w[7]*=5\n",
    "        return random.choices(c, weights=w, k=1)[0]\n",
    "\n",
    "    def _dur(self, ws):\n",
    "        mu = {\"normal\":45,\"moderate\":75,\"severe\":120,\"extreme\":200}.get(ws, 60)\n",
    "        return max(15, int(random.gauss(mu, mu*0.6)))\n",
    "\n",
    "    def _cust(self, ws):\n",
    "        s = {\"normal\":1,\"moderate\":1.5,\"severe\":3,\"extreme\":5}.get(ws, 1)\n",
    "        return max(100, int(random.lognormvariate(math.log(2000), 1.0) * s))\n",
    "\n",
    "    def generate_outage(self, location=None, timestamp=None, weather_severity=\"normal\"):\n",
    "        city = location or random.choice(self.cities)\n",
    "        ts = timestamp or datetime.utcnow()\n",
    "        dur = self._dur(weather_severity)\n",
    "        policy_zips = {\n",
    "            \"Seattle\":[\"98101\",\"98102\"], \"Portland\":[\"97201\",\"97209\"],\n",
    "            \"San Francisco\":[\"94110\",\"94111\"], \"Los Angeles\":[\"90028\",\"90401\"],\n",
    "            \"New York\":[\"10001\",\"10022\",\"11211\"],\n",
    "        }\n",
    "        zc = random.choice(policy_zips.get(city[\"name\"], [city[\"zip\"]]))\n",
    "        return {\n",
    "            \"event_id\": f\"PRESTO-{city['state']}-{ts.strftime('%Y%m%d%H%M%S')}-{random.randint(1000,9999)}\",\n",
    "            \"utility_name\": random.choice(self.utilities.get(city[\"region\"], [\"Unknown\"])),\n",
    "            \"city\": city[\"name\"], \"state\": city[\"state\"], \"zip_code\": zc,\n",
    "            \"latitude\": city[\"lat\"]+random.uniform(-0.02,0.02),\n",
    "            \"longitude\": city[\"lon\"]+random.uniform(-0.02,0.02),\n",
    "            \"affected_customers\": self._cust(weather_severity),\n",
    "            \"outage_start\": ts, \"outage_end\": ts+timedelta(minutes=dur),\n",
    "            \"duration_minutes\": dur, \"reported_cause\": self._pick_cause(weather_severity),\n",
    "            \"status\": \"resolved\", \"weather_severity\": weather_severity, \"data_source\": \"PRESTO\",\n",
    "        }\n",
    "\n",
    "    def generate_outage_scenario(self, scenario_type=\"normal_day\"):\n",
    "        cfgs = {\n",
    "            \"normal_day\":     {\"count\":(2,5),   \"sw\":[.70,.20,.08,.02]},\n",
    "            \"severe_weather\": {\"count\":(10,20),  \"sw\":[.10,.20,.50,.20]},\n",
    "            \"heat_wave\":      {\"count\":(5,15),   \"sw\":[.20,.40,.30,.10]},\n",
    "            \"winter_storm\":   {\"count\":(15,30),  \"sw\":[.05,.15,.50,.30]},\n",
    "        }\n",
    "        c = cfgs.get(scenario_type, cfgs[\"normal_day\"])\n",
    "        n = random.randint(*c[\"count\"])\n",
    "        sevs = [\"normal\",\"moderate\",\"severe\",\"extreme\"]\n",
    "        base = datetime.utcnow() - timedelta(hours=random.randint(1,6))\n",
    "        outs = [self.generate_outage(timestamp=base+timedelta(minutes=random.randint(0,360)),\n",
    "                weather_severity=random.choices(sevs, weights=c[\"sw\"], k=1)[0]) for _ in range(n)]\n",
    "        outs.sort(key=lambda x: x[\"outage_start\"])\n",
    "        return outs\n",
    "\n",
    "presto = PRESTO()\n",
    "raw_outages = presto.generate_outage_scenario(config.scenario_type)\n",
    "print(f\"âš¡ PRESTO generated {len(raw_outages)} outages for scenario: {config.scenario_type}\")\n",
    "for i, o in enumerate(raw_outages[:5], 1):\n",
    "    print(f\"  {i}. {o['city']}, {o['state']} | {o['utility_name']} | {o['affected_customers']:,} cust | {o['duration_minutes']} min | {o['reported_cause']}\")\n",
    "if len(raw_outages) > 5: print(f\"  ... and {len(raw_outages)-5} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd6813e-d3f0-4428-a1fd-02c795921eae",
   "metadata": {},
   "source": [
    "### 1b. Filter & Persist Outage Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9381995f-40b4-40e7-b5cd-b8424f4444ef",
   "metadata": {
    "collapsed": false,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "significant_outages = [o for o in raw_outages if o[\"affected_customers\"] >= config.min_customer_impact]\n",
    "print(f\"ðŸ“Š Significant outages (â‰¥{config.min_customer_impact} customers): {len(significant_outages)} / {len(raw_outages)}\")\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "outage_schema = StructType([\n",
    "    StructField(\"event_id\", StringType()), StructField(\"utility_name\", StringType()),\n",
    "    StructField(\"zip_code\", StringType()), StructField(\"city\", StringType()),\n",
    "    StructField(\"state\", StringType()), StructField(\"latitude\", DoubleType()),\n",
    "    StructField(\"longitude\", DoubleType()), StructField(\"affected_customers\", IntegerType()),\n",
    "    StructField(\"outage_start\", TimestampType()), StructField(\"outage_end\", TimestampType()),\n",
    "    StructField(\"duration_minutes\", IntegerType()), StructField(\"reported_cause\", StringType()),\n",
    "    StructField(\"status\", StringType()), StructField(\"data_source\", StringType()),\n",
    "    StructField(\"created_at\", TimestampType()), StructField(\"updated_at\", TimestampType()),\n",
    "])\n",
    "\n",
    "outage_rows = [(o[\"event_id\"], o[\"utility_name\"], o[\"zip_code\"], o[\"city\"], o[\"state\"],\n",
    "    o[\"latitude\"], o[\"longitude\"], o[\"affected_customers\"], o[\"outage_start\"], o[\"outage_end\"],\n",
    "    o[\"duration_minutes\"], o[\"reported_cause\"], o[\"status\"], o[\"data_source\"], now, now)\n",
    "    for o in significant_outages]\n",
    "\n",
    "outage_df = spark.createDataFrame(outage_rows, schema=outage_schema)\n",
    "outage_df.write.format(\"delta\").mode(\"append\").saveAsTable(\"outage_events\")\n",
    "print(f\"âœ… Persisted {len(significant_outages)} outage events.\")\n",
    "display(outage_df.select(\"event_id\",\"city\",\"state\",\"utility_name\",\"affected_customers\",\"duration_minutes\",\"reported_cause\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf0f84c-861b-4fa9-b9a0-c405cc318318",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸŒ¦ï¸ Step 2 â€” Enrich with NOAA Weather Data (free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d19e6f-58d4-42c9-ab98-2cf6f17250e1",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "def fetch_noaa_weather(lat, lon, user_agent):\n",
    "    headers = {\"User-Agent\": user_agent, \"Accept\": \"application/geo+json\"}\n",
    "    try:\n",
    "        pt = requests.get(f\"https://api.weather.gov/points/{round(lat,4)},{round(lon,4)}\", headers=headers, timeout=10)\n",
    "        pt.raise_for_status()\n",
    "        st_url = pt.json()[\"properties\"][\"observationStations\"]\n",
    "        st = requests.get(st_url, headers=headers, timeout=10); st.raise_for_status()\n",
    "        sid = st.json()[\"features\"][0][\"properties\"][\"stationIdentifier\"]\n",
    "        obs = requests.get(f\"https://api.weather.gov/stations/{sid}/observations/latest\", headers=headers, timeout=10)\n",
    "        obs.raise_for_status(); p = obs.json()[\"properties\"]\n",
    "        tc = p.get(\"temperature\",{}).get(\"value\"); tf = round(tc*9/5+32,1) if tc is not None else None\n",
    "        wm = p.get(\"windSpeed\",{}).get(\"value\"); wph = round(wm*2.237,1) if wm is not None else None\n",
    "        gm = p.get(\"windGust\",{}).get(\"value\"); gph = round(gm*2.237,1) if gm is not None else None\n",
    "        al = requests.get(f\"https://api.weather.gov/alerts/active?point={round(lat,4)},{round(lon,4)}\", headers=headers, timeout=10)\n",
    "        ad = al.json(); ha = len(ad.get(\"features\",[]))>0\n",
    "        at = ad[\"features\"][0][\"properties\"].get(\"event\") if ha else None\n",
    "        return {\"temperature_f\":tf,\"wind_speed_mph\":wph,\"wind_gust_mph\":gph,\n",
    "                \"conditions\":p.get(\"textDescription\",\"Unknown\"),\"severe_weather_alert\":ha,\"alert_type\":at}\n",
    "    except Exception as e:\n",
    "        print(f\"  âš ï¸  NOAA error ({lat},{lon}): {e}\"); return None\n",
    "\n",
    "print(\"ðŸŒ¦ï¸  Fetching NOAA weather...\")\n",
    "weather_records = []; seen = set()\n",
    "for o in significant_outages:\n",
    "    ck = f\"{o['city']}-{o['state']}\"\n",
    "    if ck in seen: continue\n",
    "    seen.add(ck)\n",
    "    w = fetch_noaa_weather(o[\"latitude\"], o[\"longitude\"], config.noaa_user_agent)\n",
    "    if w:\n",
    "        weather_records.append({\"weather_id\":f\"WX-{o['state']}-{uuid.uuid4().hex[:8]}\",\"event_id\":o[\"event_id\"],\n",
    "            \"zip_code\":o[\"zip_code\"],\"latitude\":o[\"latitude\"],\"longitude\":o[\"longitude\"],\n",
    "            \"temperature_f\":w[\"temperature_f\"],\"wind_speed_mph\":w[\"wind_speed_mph\"],\n",
    "            \"wind_gust_mph\":w[\"wind_gust_mph\"],\"conditions\":w[\"conditions\"],\n",
    "            \"severe_weather_alert\":w[\"severe_weather_alert\"],\"alert_type\":w[\"alert_type\"],\n",
    "            \"observation_time\":datetime.utcnow(),\"created_at\":now})\n",
    "        print(f\"  âœ“ {ck}: {w['temperature_f']}Â°F, wind {w['wind_speed_mph']} mph, {w['conditions']}\")\n",
    "\n",
    "weather_data_schema = StructType([\n",
    "    StructField(\"weather_id\", StringType()), StructField(\"event_id\", StringType()),\n",
    "    StructField(\"zip_code\", StringType()), StructField(\"latitude\", DoubleType()),\n",
    "    StructField(\"longitude\", DoubleType()), StructField(\"temperature_f\", DoubleType()),\n",
    "    StructField(\"wind_speed_mph\", DoubleType()), StructField(\"wind_gust_mph\", DoubleType()),\n",
    "    StructField(\"conditions\", StringType()), StructField(\"severe_weather_alert\", BooleanType()),\n",
    "    StructField(\"alert_type\", StringType()), StructField(\"observation_time\", TimestampType()),\n",
    "    StructField(\"created_at\", TimestampType())\n",
    "])\n",
    "\n",
    "if weather_records:\n",
    "    spark.createDataFrame(weather_records, weather_data_schema).write.format(\"delta\").mode(\"append\").saveAsTable(\"weather_data\")\n",
    "    print(f\"\\nâœ… Saved weather for {len(weather_records)} locations.\")\n",
    "\n",
    "weather_lookup = {}\n",
    "for wr in weather_records:\n",
    "    weather_lookup[wr[\"zip_code\"]] = wr\n",
    "    for o in significant_outages:\n",
    "        if o[\"zip_code\"] == wr[\"zip_code\"]:\n",
    "            weather_lookup[f\"{o['city']}-{o['state']}\"] = wr; break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8a1610-3467-4ece-a6fa-499aace4e75d",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ”— Step 3 â€” Match Outages â†’ Policies + Publish `outage.detected`\n",
    "# MAGIC\n",
    "When outages match policies, we publish an **`outage.detected`** event to Event Grid.\n",
    "This is the event that triggers the **ThresholdEvaluator** Azure Function in the\n",
    "production architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173ab5b5-6003-4660-8421-4fa9b1582f15",
   "metadata": {
    "collapsed": false,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "matched_df = spark.sql(\"\"\"\n",
    "    SELECT o.event_id, o.utility_name, o.city AS outage_city, o.state AS outage_state,\n",
    "           o.zip_code, o.affected_customers, o.outage_start, o.outage_end,\n",
    "           o.duration_minutes, o.reported_cause,\n",
    "           p.policy_id, p.business_name, p.business_type,\n",
    "           p.threshold_minutes, p.hourly_rate, p.max_payout,\n",
    "           (o.duration_minutes - p.threshold_minutes) AS excess_minutes\n",
    "    FROM outage_events o\n",
    "    INNER JOIN policies p ON o.zip_code = p.zip_code\n",
    "    WHERE p.status = 'active' AND o.duration_minutes > p.threshold_minutes\n",
    "    ORDER BY o.duration_minutes DESC\n",
    "\"\"\")\n",
    "\n",
    "matched_count = matched_df.count()\n",
    "matches = matched_df.collect() if matched_count > 0 else []\n",
    "print(f\"ðŸ”— {matched_count} policy matches where outage exceeded threshold.\")\n",
    "\n",
    "if matched_count > 0:\n",
    "    display(matched_df)\n",
    "\n",
    "    # ---- Publish outage.detected events to Event Grid ----\n",
    "    # Group by event_id so we send one event per outage (with all affected policies)\n",
    "    outage_to_policies = {}\n",
    "    for m in matches:\n",
    "        md = m.asDict()\n",
    "        eid = md[\"event_id\"]\n",
    "        if eid not in outage_to_policies:\n",
    "            outage_to_policies[eid] = {\n",
    "                \"event_id\": eid,\n",
    "                \"utility_name\": md[\"utility_name\"],\n",
    "                \"city\": md[\"outage_city\"],\n",
    "                \"state\": md[\"outage_state\"],\n",
    "                \"zip_code\": md[\"zip_code\"],\n",
    "                \"affected_customers\": md[\"affected_customers\"],\n",
    "                \"outage_start\": str(md[\"outage_start\"]),\n",
    "                \"duration_minutes\": md[\"duration_minutes\"],\n",
    "                \"reported_cause\": md[\"reported_cause\"],\n",
    "                \"affected_policies\": [],\n",
    "            }\n",
    "        outage_to_policies[eid][\"affected_policies\"].append(md[\"policy_id\"])\n",
    "\n",
    "    print(f\"\\nðŸ“¡ Publishing {len(outage_to_policies)} 'outage.detected' events...\")\n",
    "    for eid, data in outage_to_policies.items():\n",
    "        data[\"policy_count\"] = len(data[\"affected_policies\"])\n",
    "        ok = eg_client.publish_event(\n",
    "            event_type=config.EVT_OUTAGE_DETECTED,\n",
    "            subject=f\"outage/{eid}\",\n",
    "            data=data,\n",
    "        )\n",
    "        status = \"âœ…\" if ok else \"âš ï¸\"\n",
    "        print(f\"  {status} outage.detected â†’ {eid} | {data['city']}, {data['state']} | {data['policy_count']} policies\")\n",
    "\n",
    "    print(f\"\\nâœ… Event Grid: {len(outage_to_policies)} outage.detected events published.\")\n",
    "else:\n",
    "    print(\"   â„¹ï¸  No matches â€” try 'severe_weather' or 'winter_storm' scenario.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfcbb5d-ee13-4e77-8270-0c6e1960448a",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ¤– Step 4 â€” AI Claim Validation + Publish `claim.approved` / `claim.denied`\n",
    "# MAGIC\n",
    "After validating each claim (via Foundry Agent or rule-based engine), we publish\n",
    "either a **`claim.approved`** or **`claim.denied`** event. In the production\n",
    "architecture, `claim.approved` triggers the **PayoutProcessor** Azure Function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2030e9e-46bc-498b-9996-ac45b0861f73",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "def extract_response_text(response):\n",
    "    if not response.output:\n",
    "        return \"\"\n",
    "\n",
    "    return \"\".join(\n",
    "        content.text\n",
    "        for item in response.output\n",
    "        for content in getattr(item, \"content\", [])\n",
    "        if getattr(content, \"type\", \"\") == \"output_text\"\n",
    "    )\n",
    "\n",
    "def calculate_weather_factor(weather):\n",
    "    if not weather: return 1.0, \"unknown\"\n",
    "    wind = weather.get(\"wind_speed_mph\") or 0; gust = weather.get(\"wind_gust_mph\") or 0\n",
    "    ha = weather.get(\"severe_weather_alert\", False); at = str(weather.get(\"alert_type\",\"\"))\n",
    "    mx = max(wind, gust)\n",
    "    if ha and (\"Severe\" in at or \"Hurricane\" in at or mx>55): return 1.5, \"severe\"\n",
    "    elif ha or mx>40: return 1.2, \"high\"\n",
    "    elif mx>25: return 1.1, \"medium\"\n",
    "    return 1.0, \"low\"\n",
    "\n",
    "def rule_based_validation(policy, outage, weather=None):\n",
    "    dur = outage[\"duration_minutes\"]; thr = policy[\"threshold_minutes\"]; excess = dur - thr\n",
    "    if excess <= 0:\n",
    "        return {\"decision\":\"denied\",\"confidence_score\":0.95,\"payout_amount\":0.0,\n",
    "                \"reasoning\":f\"Duration ({dur} min) < threshold ({thr} min).\",\n",
    "                \"severity_assessment\":\"none\",\"weather_factor\":1.0,\"fraud_signals\":[],\"evidence\":[]}\n",
    "    wf, sev = calculate_weather_factor(weather)\n",
    "    raw = (excess/60.0) * policy[\"hourly_rate\"] * wf\n",
    "    final = min(raw, policy[\"max_payout\"])\n",
    "    fraud = [\"planned_maintenance_not_covered\"] if outage.get(\"reported_cause\") == \"planned_maintenance\" else []\n",
    "    conf = min(0.92 + (0.03 if weather else 0) + (0.02 if outage.get(\"affected_customers\",0)>5000 else 0), 0.99)\n",
    "    dec = \"denied\" if outage.get(\"reported_cause\") == \"planned_maintenance\" else \"approved\"\n",
    "    return {\"decision\":dec,\"confidence_score\":round(conf,4),\"payout_amount\":round(final,2),\n",
    "            \"reasoning\":f\"Outage {dur} min, threshold {thr} min, excess {excess} min. Weather: {sev} ({wf}x). Payout: ${final:,.2f}.\",\n",
    "            \"severity_assessment\":sev,\"weather_factor\":wf,\"fraud_signals\":fraud,\n",
    "            \"evidence\":[{\"type\":\"duration\",\"value\":f\"{dur} min\"},{\"type\":\"threshold\",\"value\":f\"{thr} min\"},\n",
    "                        {\"type\":\"weather\",\"value\":f\"{sev} ({wf}x)\"},{\"type\":\"payout\",\"value\":f\"${final:,.2f}\"}]}\n",
    "\n",
    "def foundry_agent_validation(policy, outage, weather=None):\n",
    "    try:\n",
    "        from azure.ai.projects import AIProjectClient\n",
    "        from azure.identity import DefaultAzureCredential # <--- One day this will work with the Workspace Identity from within a Fabric notebook\n",
    "    except ImportError:\n",
    "        return rule_based_validation(policy, outage, weather)\n",
    "\n",
    "    if not config.foundry_endpoint or not config.foundry_agent:\n",
    "        return rule_based_validation(policy, outage, weather)\n",
    "\n",
    "    try:\n",
    "        project_client = AIProjectClient(\n",
    "            endpoint=config.foundry_endpoint,\n",
    "            credential=DefaultAzureCredential() # <--- One day this will work with the Workspace Identity from within a Fabric notebook\n",
    "        )\n",
    "\n",
    "        user_prompt = f\"\"\"POLICY: {json.dumps(policy, default=str)}\n",
    "                          OUTAGE: {json.dumps(outage, default=str)}\n",
    "                          WEATHER: {json.dumps(weather, default=str) if weather else \"N/A\"}\"\"\"\n",
    "\n",
    "        claims_validator_agent = project_client.agents.get(agent_name=config.foundry_agent)\n",
    "\n",
    "        claims_validator_client = project_client.get_openai_client()\n",
    "\n",
    "        # ---- Call Responses API with Agent Reference ----\n",
    "        response = claims_validator_client.responses.create(\n",
    "            input=[{\"role\": \"user\", \"content\": user_prompt}],\n",
    "            extra_body={\n",
    "                \"agent\": {\n",
    "                    \"name\": claims_validator_agent.name,\n",
    "                    \"type\": \"agent_reference\"\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "\n",
    "        txt = extract_response_text(response)\n",
    "\n",
    "        if not txt:\n",
    "            print(\"  âš ï¸  Foundry agent returned no response\")\n",
    "            return rule_based_validation(policy, outage, weather)\n",
    "\n",
    "        # Clean markdown fences if present\n",
    "        txt = txt.strip()\n",
    "        if txt.startswith(\"```\"):\n",
    "            txt = txt.split(\"\\n\", 1)[1].rsplit(\"```\", 1)[0].strip()\n",
    "\n",
    "        print(f\" Response from {claims_validator_agent.name}: {txt}\")\n",
    "\n",
    "        return json.loads(txt)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  âš ï¸  Foundry agent error: {e}\")\n",
    "        return rule_based_validation(policy, outage, weather)\n",
    "\n",
    "# ---- Validate all matched claims ----\n",
    "print(f\"ðŸ¤– Validating {len(matches)} claims...\")\n",
    "print(f\"   Method: {'Foundry Agent' if config.foundry_endpoint else 'Rule-Based Engine'}\\n\")\n",
    "\n",
    "claim_records = []\n",
    "for i, match in enumerate(matches, 1):\n",
    "    m = match.asDict()\n",
    "    pd_dict = {\"policy_id\":m[\"policy_id\"],\"business_name\":m[\"business_name\"],\n",
    "               \"threshold_minutes\":m[\"threshold_minutes\"],\"hourly_rate\":m[\"hourly_rate\"],\"max_payout\":m[\"max_payout\"]}\n",
    "    od_dict = {\"event_id\":m[\"event_id\"],\"utility_name\":m[\"utility_name\"],\"duration_minutes\":m[\"duration_minutes\"],\n",
    "               \"affected_customers\":m[\"affected_customers\"],\"reported_cause\":m[\"reported_cause\"],\n",
    "               \"outage_start\":str(m[\"outage_start\"]),\"status\":\"resolved\"}\n",
    "    wd = weather_lookup.get(m[\"zip_code\"]) or weather_lookup.get(f\"{m['outage_city']}-{m['outage_state']}\")\n",
    "\n",
    "    result = foundry_agent_validation(pd_dict, od_dict, wd)\n",
    "\n",
    "    cid = f\"CLM-{uuid.uuid4().hex[:8].upper()}\"\n",
    "    ct = datetime.utcnow()\n",
    "    claim = {\n",
    "        \"claim_id\":cid, \"policy_id\":m[\"policy_id\"], \"outage_event_id\":m[\"event_id\"],\n",
    "        \"status\":result[\"decision\"], \"filed_at\":ct,\n",
    "        \"validated_at\":ct+timedelta(seconds=random.randint(5,30)),\n",
    "        \"approved_at\":(ct+timedelta(seconds=random.randint(10,45))) if result[\"decision\"]==\"approved\" else None,\n",
    "        \"denied_at\":(ct+timedelta(seconds=10)) if result[\"decision\"]==\"denied\" else None,\n",
    "        \"denial_reason\":result[\"reasoning\"] if result[\"decision\"]==\"denied\" else None,\n",
    "        \"payout_amount\":result[\"payout_amount\"], \"ai_confidence_score\":result[\"confidence_score\"],\n",
    "        \"ai_reasoning\":result[\"reasoning\"], \"fraud_flags\":json.dumps(result.get(\"fraud_signals\",[])),\n",
    "        \"weather_factor\":result.get(\"weather_factor\",1.0), \"severity_assessment\":result.get(\"severity_assessment\",\"unknown\"),\n",
    "        \"created_at\":ct, \"updated_at\":ct,\n",
    "    }\n",
    "    claim_records.append(claim)\n",
    "\n",
    "    icon = \"âœ…\" if result[\"decision\"]==\"approved\" else \"âŒ\"\n",
    "    print(f\"  {i}. {icon} {m['business_name']} ({m['policy_id']})\")\n",
    "    print(f\"     Outage: {m['duration_minutes']} min (threshold: {m['threshold_minutes']})\")\n",
    "    print(f\"     Decision: {result['decision'].upper()} | Confidence: {result['confidence_score']:.1%} | Payout: ${result['payout_amount']:,.2f}\")\n",
    "\n",
    "    # ---- Publish claim.approved or claim.denied ----\n",
    "    evt_type = config.EVT_CLAIM_APPROVED if result[\"decision\"] == \"approved\" else config.EVT_CLAIM_DENIED\n",
    "    eg_client.publish_event(\n",
    "        event_type=evt_type,\n",
    "        subject=f\"claim/{cid}\",\n",
    "        data={\n",
    "            \"claim_id\": cid,\n",
    "            \"policy_id\": m[\"policy_id\"],\n",
    "            \"outage_event_id\": m[\"event_id\"],\n",
    "            \"status\": result[\"decision\"],\n",
    "            \"payout_amount\": result[\"payout_amount\"],\n",
    "            \"ai_confidence_score\": result[\"confidence_score\"],\n",
    "            \"severity_assessment\": result.get(\"severity_assessment\"),\n",
    "            \"weather_factor\": result.get(\"weather_factor\", 1.0),\n",
    "            \"business_name\": m[\"business_name\"],\n",
    "            \"city\": m[\"outage_city\"],\n",
    "            \"state\": m[\"outage_state\"]\n",
    "        },\n",
    "    )\n",
    "    print(f\"     ðŸ“¡ Published: {evt_type}\")\n",
    "    print()\n",
    "\n",
    "if claim_records:\n",
    "    claim_schema = StructType([\n",
    "        StructField(\"claim_id\", StringType()),\n",
    "        StructField(\"policy_id\", StringType()), \n",
    "        StructField(\"outage_event_id\", StringType()),\n",
    "        StructField(\"status\", StringType()), \n",
    "        StructField(\"filed_at\", TimestampType()), \n",
    "        StructField(\"validated_at\", TimestampType()),\n",
    "        StructField(\"approved_at\", TimestampType()), \n",
    "        StructField(\"denied_at\", TimestampType()), \n",
    "        StructField(\"denial_reason\", StringType()),\n",
    "        StructField(\"payout_amount\", DoubleType()), \n",
    "        StructField(\"ai_confidence_score\", DoubleType()), \n",
    "        StructField(\"ai_reasoning\", StringType()),\n",
    "        StructField(\"fraud_flags\", StringType()), \n",
    "        StructField(\"weather_factor\", DoubleType()), \n",
    "        StructField(\"severity_assessment\", StringType()),\n",
    "        StructField(\"created_at\", TimestampType()), \n",
    "        StructField(\"updated_at\", TimestampType())\n",
    "\n",
    "    ])\n",
    "    spark.createDataFrame(claim_records, claim_schema).write.format(\"delta\").mode(\"append\").saveAsTable(\"claims\")\n",
    "    approved_count = sum(1 for c in claim_records if c[\"status\"]==\"approved\")\n",
    "    denied_count = len(claim_records) - approved_count\n",
    "    print(f\"âœ… Persisted {len(claim_records)} claims ({approved_count} approved, {denied_count} denied).\")\n",
    "    print(f\"ðŸ“¡ Published {len(claim_records)} claim events to Event Grid.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d39a4ad-e459-48d3-9644-5a53ef64b1d3",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ’° Step 5 â€” Process Payouts + Publish `payout.processed`\n",
    "# MAGIC\n",
    "For each approved claim, we create a payout record and publish a\n",
    "**`payout.processed`** event to Event Grid. In production, this event can\n",
    "trigger notifications (email, SMS) via Logic Apps or additional Functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2c6e6d-c0df-406e-b03a-0868b51db585",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "approved_claims = [c for c in claim_records if c[\"status\"] == \"approved\"]\n",
    "print(f\"ðŸ’° Processing {len(approved_claims)} approved payouts...\\n\")\n",
    "\n",
    "payout_records = []\n",
    "total_payout = 0.0\n",
    "\n",
    "for claim in approved_claims:\n",
    "    pt = datetime.utcnow()\n",
    "    payout = {\n",
    "        \"payout_id\": f\"PAY-{uuid.uuid4().hex[:8].upper()}\",\n",
    "        \"claim_id\": claim[\"claim_id\"],\n",
    "        \"policy_id\": claim[\"policy_id\"],\n",
    "        \"amount\": claim[\"payout_amount\"],\n",
    "        \"status\": \"completed\",\n",
    "        \"initiated_at\": pt,\n",
    "        \"completed_at\": pt + timedelta(seconds=random.randint(2, 15)),\n",
    "        \"transaction_id\": f\"TXN-{uuid.uuid4().hex[:12].upper()}\",\n",
    "        \"payment_method\": \"ACH\",\n",
    "        \"created_at\": pt,\n",
    "    }\n",
    "    payout_records.append(payout)\n",
    "    total_payout += claim[\"payout_amount\"]\n",
    "\n",
    "    print(f\"  ðŸ’³ {payout['payout_id']} â†’ {claim['policy_id']} | ${claim['payout_amount']:,.2f} | TXN: {payout['transaction_id']}\")\n",
    "\n",
    "    # ---- Publish payout.processed ----\n",
    "    eg_client.publish_event(\n",
    "        event_type=config.EVT_PAYOUT_PROCESSED,\n",
    "        subject=f\"payout/{payout['payout_id']}\",\n",
    "        data={\n",
    "            \"payout_id\": payout[\"payout_id\"],\n",
    "            \"claim_id\": claim[\"claim_id\"],\n",
    "            \"policy_id\": claim[\"policy_id\"],\n",
    "            \"amount\": claim[\"payout_amount\"],\n",
    "            \"transaction_id\": payout[\"transaction_id\"],\n",
    "            \"payment_method\": \"ACH\",\n",
    "            \"status\": \"completed\",\n",
    "            \"initiated_at\": str(payout[\"initiated_at\"]),\n",
    "            \"completed_at\": str(payout[\"completed_at\"]),\n",
    "        },\n",
    "    )\n",
    "    print(f\"     ðŸ“¡ Published: payout.processed\")\n",
    "\n",
    "if payout_records:\n",
    "    spark.createDataFrame(payout_records).write.format(\"delta\").mode(\"append\").saveAsTable(\"payouts\")\n",
    "    print(f\"\\nâœ… {len(payout_records)} payouts completed. Total: ${total_payout:,.2f}\")\n",
    "    print(f\"ðŸ“¡ Published {len(payout_records)} payout.processed events.\")\n",
    "else:\n",
    "    print(\"â„¹ï¸  No payouts to process.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e00ebe-8398-495c-93ad-de978cfe652d",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ“‹ Step 6 â€” Persist Event Audit Log & Dashboard Summary\n",
    "# MAGIC\n",
    "Every event (published or local-only) is stored in the `event_audit_log` table\n",
    "for full traceability and compliance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9fa77f-df98-4c88-acd6-527f46a7898c",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# ---- Persist audit log to Delta ----\n",
    "now = datetime.now()\n",
    "if eg_client.audit_log:\n",
    "    audit_rows = [{**a, \"created_at\": now} for a in eg_client.audit_log]\n",
    "    audit_rows_schema = StructType([\n",
    "        StructField(\"sequence\", IntegerType()),\n",
    "        StructField(\"event_id\", StringType()), \n",
    "        StructField(\"event_type\", StringType()),\n",
    "        StructField(\"subject\", StringType()), \n",
    "        StructField(\"event_time\", StringType()),\n",
    "        StructField(\"data_summary\", StringType()), \n",
    "        StructField(\"status\", StringType()), \n",
    "        StructField(\"error\", StringType()),\n",
    "        StructField(\"created_at\", TimestampType())\n",
    "    ])\n",
    "    spark.createDataFrame(audit_rows, audit_rows_schema).write.format(\"delta\").mode(\"append\").saveAsTable(\"event_audit_log\")\n",
    "    print(f\"âœ… Persisted {len(audit_rows)} event audit records.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e287f8-6a88-4bcf-98e5-f8dc408f0bf6",
   "metadata": {},
   "source": [
    "### Event Audit Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca69896-dd35-4d81-9b0d-4f019e880491",
   "metadata": {
    "collapsed": false,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql(\"\"\"\n",
    "    SELECT sequence, event_type, subject, status, event_time, error,\n",
    "           SUBSTRING(data_summary, 1, 120) AS data_preview\n",
    "    FROM event_audit_log\n",
    "    ORDER BY sequence\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52149f2-3982-4d27-b865-5519c9a09ed3",
   "metadata": {},
   "source": [
    "### Event Grid Summary by Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2113ebff-f857-44ab-9fd3-087a21a1abcc",
   "metadata": {
    "collapsed": false,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        event_type,\n",
    "        status,\n",
    "        COUNT(*) AS event_count\n",
    "    FROM event_audit_log\n",
    "    WHERE event_type != 'test.connection'\n",
    "    GROUP BY event_type, status\n",
    "    ORDER BY event_type, status\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab252ab6-ac12-47d0-92fc-f54880692131",
   "metadata": {},
   "source": [
    "### Execution Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d478a7-288d-441f-ba60-43ab9322e537",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"ðŸ“Š  PARAMETRIC INSURANCE DEMO â€” EXECUTION SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"  Timestamp:           {datetime.utcnow().isoformat()}Z\")\n",
    "print(f\"  Scenario:            {config.scenario_type}\")\n",
    "print(f\"  Validation Method:   {'Foundry Agent' if config.foundry_endpoint else 'Rule-Based Engine'}\")\n",
    "print(f\"  Event Grid:          {'ENABLED' if EVENTGRID_ENABLED else 'LOCAL-ONLY'}\")\n",
    "print()\n",
    "print(f\"  âš¡ Outages Generated:   {len(raw_outages)}\")\n",
    "print(f\"  âš¡ Significant Outages:  {len(significant_outages)}\")\n",
    "print(f\"  ðŸŒ¦ï¸  Weather Records:     {len(weather_records)}\")\n",
    "print(f\"  ðŸ”— Policy Matches:      {matched_count}\")\n",
    "print(f\"  ðŸ¤– Claims Filed:        {len(claim_records)}\")\n",
    "print(f\"  âœ… Claims Approved:     {len(approved_claims)}\")\n",
    "print(f\"  âŒ Claims Denied:       {len(claim_records) - len(approved_claims)}\")\n",
    "print(f\"  ðŸ’° Payouts Processed:   {len(payout_records)}\")\n",
    "print(f\"  ðŸ’° Total Disbursed:     ${total_payout:,.2f}\")\n",
    "print()\n",
    "total_events = len([a for a in eg_client.audit_log if a[\"event_type\"] != \"test.connection\"])\n",
    "published = len([a for a in eg_client.audit_log if a[\"status\"] == \"published\"])\n",
    "local = len([a for a in eg_client.audit_log if a[\"status\"] == \"local_only\"])\n",
    "failed = len([a for a in eg_client.audit_log if a[\"status\"] == \"failed\"])\n",
    "print(f\"  ðŸ“¡ Events Total:        {total_events}\")\n",
    "print(f\"  ðŸ“¡ Events Published:    {published}\")\n",
    "print(f\"  ðŸ“ Events Local-Only:   {local}\")\n",
    "if failed: print(f\"  âš ï¸  Events Failed:       {failed}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1270048-972f-4507-bf02-8794ba911772",
   "metadata": {},
   "source": [
    "### Claims Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299639ca-04b2-4d9a-b18d-2011459d9f59",
   "metadata": {
    "collapsed": false,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "if claim_records:\n",
    "    display(spark.sql(\"\"\"\n",
    "        SELECT c.claim_id, c.policy_id, p.business_name, p.city, c.status,\n",
    "               c.payout_amount, c.ai_confidence_score, c.severity_assessment, c.weather_factor\n",
    "        FROM claims c JOIN policies p ON c.policy_id = p.policy_id ORDER BY c.payout_amount DESC\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d716fc9-58c5-4444-9d3d-4995e8c7ef5e",
   "metadata": {},
   "source": [
    "### Payout Summary by City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363a1394-c330-4010-9906-afb42fd930be",
   "metadata": {
    "collapsed": false,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "if payout_records:\n",
    "    display(spark.sql(\"\"\"\n",
    "        SELECT p.city, p.state, COUNT(pay.payout_id) AS payouts,\n",
    "               SUM(pay.amount) AS total, AVG(pay.amount) AS avg_payout\n",
    "        FROM payouts pay JOIN claims c ON pay.claim_id=c.claim_id\n",
    "        JOIN policies p ON c.policy_id=p.policy_id\n",
    "        GROUP BY p.city, p.state ORDER BY total DESC\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a528be20-6803-4255-95ff-fc6fa31afdde",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ Demo Complete!\n",
    "# MAGIC\n",
    "### Event-Driven Architecture\n",
    "# MAGIC\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    outage.detected     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  PRESTO  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚ ThresholdEvaluator  â”‚\n",
    "â”‚ + Fabric â”‚                         â”‚  (Azure Function)   â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                                              â”‚\n",
    "                                   claim.approved / claim.denied\n",
    "                                              â”‚\n",
    "                                              â–¼\n",
    "                                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                                     â”‚  PayoutProcessor   â”‚\n",
    "                                     â”‚  (Azure Function)  â”‚\n",
    "                                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                                              â”‚\n",
    "                                     payout.processed\n",
    "                                              â”‚\n",
    "                                              â–¼\n",
    "                                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                                     â”‚  Notifications     â”‚\n",
    "                                     â”‚  (Logic App/Email) â”‚\n",
    "                                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "# MAGIC\n",
    "### Event Grid Subscriptions (configured via azure-setup.sh)\n",
    "# MAGIC\n",
    "| Event Type | Subscriber | Action |\n",
    "|-----------|-----------|--------|\n",
    "| `outage.detected` | ThresholdEvaluator Function | Evaluate thresholds, call AI agent |\n",
    "| `claim.approved` | PayoutProcessor Function | Process payment |\n",
    "| `claim.denied` | (optional) Audit Logger | Record denial |\n",
    "| `payout.processed` | (optional) Logic App | Send email/SMS notification |\n",
    "# MAGIC\n",
    "### Next Steps\n",
    "- **Wire Azure Functions:** Deploy the ThresholdEvaluator and PayoutProcessor functions\n",
    "- **Fabric Data Agent:** Create a natural-language agent on top of these Delta tables\n",
    "- **Foundry Agent:** Deploy the claims validator as a standalone Foundry Agent\n",
    "- **Power BI:** Connect a dashboard for real-time monitoring\n",
    "- **Logic Apps:** Add email/SMS notifications on `payout.processed`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d9952e-cdf1-4d3b-8714-9fc65790231c",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Return for pipeline orchestration\n",
    "if FABRIC_ENV:\n",
    "    mssparkutils.notebook.exit(json.dumps({\n",
    "        \"status\": \"success\",\n",
    "        \"scenario\": config.scenario_type,\n",
    "        \"event_grid_enabled\": EVENTGRID_ENABLED,\n",
    "        \"outages_generated\": len(raw_outages),\n",
    "        \"significant_outages\": len(significant_outages),\n",
    "        \"policy_matches\": matched_count,\n",
    "        \"claims_filed\": len(claim_records),\n",
    "        \"claims_approved\": len(approved_claims),\n",
    "        \"payouts_processed\": len(payout_records),\n",
    "        \"total_disbursed\": total_payout,\n",
    "        \"events_published\": published,\n",
    "        \"events_failed\": failed,\n",
    "        \"timestamp\": datetime.utcnow().isoformat(),\n",
    "    }))\n",
    "else:\n",
    "    print(\"\\nðŸ Notebook execution complete.\")"
   ]
  }
 ],
 "metadata": {
  "a365ComputeOptions": null,
  "dependencies": {
   "lakehouse": {
    "default_lakehouse": "5166d063-e222-49b7-948b-f029f463cc2b",
    "default_lakehouse_name": "parametric_insurance_lakehouse",
    "default_lakehouse_workspace_id": "c244c53e-58d3-4055-8dc8-8c79bc0ad4b0",
    "known_lakehouses": [
     {
      "id": "5166d063-e222-49b7-948b-f029f463cc2b"
     }
    ]
   }
  },
  "kernel_info": {
   "jupyter_kernel_name": null,
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "sessionKeepAliveTimeout": 0,
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  },
  "synapse_widget": {
   "state": {
    "29eb9665-a063-4d8d-b840-ec169315831f": {
     "persist_state": {
      "view": {
       "chartOptions": {
        "aggregationType": "sum",
        "binsNumber": 10,
        "categoryFieldKeys": [],
        "chartType": "bar",
        "isStacked": false,
        "seriesFieldKeys": [],
        "wordFrequency": "-1"
       },
       "tableOptions": {},
       "type": "details",
       "viewOptionsGroup": [
        {
         "tabItems": [
          {
           "key": "0",
           "name": "Table",
           "options": {},
           "type": "table"
          }
         ]
        }
       ]
      }
     },
     "sync_state": {
      "isSummary": false,
      "language": "scala",
      "table": {
       "rows": [
        {
         "0": "San Francisco",
         "1": "CA",
         "2": "2",
         "3": "53800.0",
         "4": "26900.0"
        }
       ],
       "schema": [
        {
         "key": "0",
         "name": "city",
         "type": "string"
        },
        {
         "key": "1",
         "name": "state",
         "type": "string"
        },
        {
         "key": "2",
         "name": "payouts",
         "type": "bigint"
        },
        {
         "key": "3",
         "name": "total",
         "type": "double"
        },
        {
         "key": "4",
         "name": "avg_payout",
         "type": "double"
        }
       ],
       "truncated": false
      },
      "wranglerEntryContext": {
       "dataframeType": "pyspark"
      }
     },
     "type": "Synapse.DataFrame"
    },
    "3af64faa-1a55-4d35-a72d-a347382bcb5e": {
     "persist_state": {
      "view": {
       "chartOptions": {
        "aggregationType": "sum",
        "binsNumber": 10,
        "categoryFieldKeys": [],
        "chartType": "bar",
        "isStacked": false,
        "seriesFieldKeys": [],
        "wordFrequency": "-1"
       },
       "tableOptions": {},
       "type": "details",
       "viewOptionsGroup": [
        {
         "tabItems": [
          {
           "key": "0",
           "name": "Table",
           "options": {},
           "type": "table"
          }
         ]
        }
       ]
      }
     },
     "sync_state": {
      "isSummary": false,
      "language": "scala",
      "table": {
       "rows": [
        {
         "0": "PRESTO-MI-20260212151937-3861",
         "1": "Detroit",
         "2": "MI",
         "3": "ComEd",
         "4": "5353",
         "5": "50",
         "6": "animal_contact"
        },
        {
         "0": "PRESTO-FL-20260212153137-2907",
         "1": "Miami",
         "2": "FL",
         "3": "Entergy",
         "4": "7066",
         "5": "26",
         "6": "equipment_failure"
        },
        {
         "0": "PRESTO-CA-20260212154437-8757",
         "1": "San Francisco",
         "2": "CA",
         "3": "Southern California Edison",
         "4": "15655",
         "5": "154",
         "6": "tree_contact"
        },
        {
         "0": "PRESTO-PA-20260212155237-7107",
         "1": "Philadelphia",
         "2": "PA",
         "3": "BGE",
         "4": "2272",
         "5": "66",
         "6": "tree_contact"
        },
        {
         "0": "PRESTO-DC-20260212165137-4233",
         "1": "Washington",
         "2": "DC",
         "3": "Pepco",
         "4": "2317",
         "5": "59",
         "6": "lightning"
        },
        {
         "0": "PRESTO-CA-20260212165837-4029",
         "1": "San Francisco",
         "2": "CA",
         "3": "Southern California Edison",
         "4": "1045",
         "5": "87",
         "6": "overload"
        },
        {
         "0": "PRESTO-OR-20260212173337-2529",
         "1": "Portland",
         "2": "OR",
         "3": "Portland General Electric",
         "4": "1343",
         "5": "23",
         "6": "storm_damage"
        },
        {
         "0": "PRESTO-AZ-20260212175337-9072",
         "1": "Phoenix",
         "2": "AZ",
         "3": "NV Energy",
         "4": "6285",
         "5": "66",
         "6": "storm_damage"
        },
        {
         "0": "PRESTO-GA-20260212180937-8416",
         "1": "Atlanta",
         "2": "GA",
         "3": "Duke Energy Carolinas",
         "4": "8291",
         "5": "221",
         "6": "overload"
        },
        {
         "0": "PRESTO-CA-20260212181037-3032",
         "1": "Los Angeles",
         "2": "CA",
         "3": "LADWP",
         "4": "5182",
         "5": "60",
         "6": "equipment_failure"
        },
        {
         "0": "PRESTO-CO-20260212184037-7586",
         "1": "Denver",
         "2": "CO",
         "3": "Black Hills Energy",
         "4": "3757",
         "5": "15",
         "6": "equipment_failure"
        },
        {
         "0": "PRESTO-IL-20260212190037-4757",
         "1": "Chicago",
         "2": "IL",
         "3": "Duke Energy Ohio",
         "4": "2907",
         "5": "15",
         "6": "storm_damage"
        },
        {
         "0": "PRESTO-CO-20260212202737-3478",
         "1": "Denver",
         "2": "CO",
         "3": "Rocky Mountain Power",
         "4": "4926",
         "5": "15",
         "6": "storm_damage"
        },
        {
         "0": "PRESTO-NY-20260212203937-5300",
         "1": "New York",
         "2": "NY",
         "3": "Eversource Energy",
         "4": "1216",
         "5": "78",
         "6": "tree_contact"
        },
        {
         "0": "PRESTO-PA-20260212204437-1661",
         "1": "Philadelphia",
         "2": "PA",
         "3": "Pepco",
         "4": "3219",
         "5": "235",
         "6": "storm_damage"
        },
        {
         "0": "PRESTO-TX-20260212205637-7500",
         "1": "Austin",
         "2": "TX",
         "3": "CenterPoint Energy",
         "4": "1996",
         "5": "48",
         "6": "equipment_failure"
        }
       ],
       "schema": [
        {
         "key": "0",
         "name": "event_id",
         "type": "string"
        },
        {
         "key": "1",
         "name": "city",
         "type": "string"
        },
        {
         "key": "2",
         "name": "state",
         "type": "string"
        },
        {
         "key": "3",
         "name": "utility_name",
         "type": "string"
        },
        {
         "key": "4",
         "name": "affected_customers",
         "type": "int"
        },
        {
         "key": "5",
         "name": "duration_minutes",
         "type": "int"
        },
        {
         "key": "6",
         "name": "reported_cause",
         "type": "string"
        }
       ],
       "truncated": false
      },
      "wranglerEntryContext": {
       "dataframeType": "pyspark"
      }
     },
     "type": "Synapse.DataFrame"
    },
    "652ed788-bae9-4d8c-bb12-ce68133776c8": {
     "persist_state": {
      "view": {
       "chartOptions": {
        "aggregationType": "sum",
        "binsNumber": 10,
        "categoryFieldKeys": [],
        "chartType": "bar",
        "isStacked": false,
        "seriesFieldKeys": [],
        "wordFrequency": "-1"
       },
       "tableOptions": {},
       "type": "details",
       "viewOptionsGroup": [
        {
         "tabItems": [
          {
           "key": "0",
           "name": "Table",
           "options": {},
           "type": "table"
          }
         ]
        }
       ]
      }
     },
     "sync_state": {
      "isSummary": false,
      "language": "scala",
      "table": {
       "rows": [
        {
         "0": "BI-011",
         "1": "Brooklyn Artisan Market",
         "2": "Brooklyn",
         "3": "NY",
         "4": "120",
         "5": "400.0",
         "6": "9000.0"
        },
        {
         "0": "BI-009",
         "1": "Hollywood Production Studio",
         "2": "Los Angeles",
         "3": "CA",
         "4": "60",
         "5": "1500.0",
         "6": "40000.0"
        },
        {
         "0": "BI-010",
         "1": "Manhattan Fine Dining",
         "2": "New York",
         "3": "NY",
         "4": "45",
         "5": "1200.0",
         "6": "30000.0"
        },
        {
         "0": "BI-005",
         "1": "Pearl District Co-Working",
         "2": "Portland",
         "3": "OR",
         "4": "240",
         "5": "400.0",
         "6": "20000.0"
        },
        {
         "0": "BI-004",
         "1": "Downtown Portland Bakery",
         "2": "Portland",
         "3": "OR",
         "4": "90",
         "5": "600.0",
         "6": "12000.0"
        },
        {
         "0": "BI-006",
         "1": "Mission District Brewery",
         "2": "San Francisco",
         "3": "CA",
         "4": "120",
         "5": "900.0",
         "6": "25000.0"
        },
        {
         "0": "BI-007",
         "1": "Financial District Data Center",
         "2": "San Francisco",
         "3": "CA",
         "4": "30",
         "5": "2000.0",
         "6": "50000.0"
        },
        {
         "0": "BI-008",
         "1": "Santa Monica Beach Cafe",
         "2": "Santa Monica",
         "3": "CA",
         "4": "90",
         "5": "550.0",
         "6": "10000.0"
        },
        {
         "0": "BI-001",
         "1": "Pike Place Coffee Co",
         "2": "Seattle",
         "3": "WA",
         "4": "120",
         "5": "500.0",
         "6": "10000.0"
        },
        {
         "0": "BI-003",
         "1": "Capitol Hill Fitness Center",
         "2": "Seattle",
         "3": "WA",
         "4": "180",
         "5": "300.0",
         "6": "8000.0"
        },
        {
         "0": "BI-002",
         "1": "Broadway Restaurant & Bar",
         "2": "Seattle",
         "3": "WA",
         "4": "60",
         "5": "750.0",
         "6": "15000.0"
        }
       ],
       "schema": [
        {
         "key": "0",
         "name": "policy_id",
         "type": "string"
        },
        {
         "key": "1",
         "name": "business_name",
         "type": "string"
        },
        {
         "key": "2",
         "name": "city",
         "type": "string"
        },
        {
         "key": "3",
         "name": "state",
         "type": "string"
        },
        {
         "key": "4",
         "name": "threshold_minutes",
         "type": "int"
        },
        {
         "key": "5",
         "name": "hourly_rate",
         "type": "double"
        },
        {
         "key": "6",
         "name": "max_payout",
         "type": "double"
        }
       ],
       "truncated": false
      },
      "wranglerEntryContext": {
       "dataframeType": "pyspark"
      }
     },
     "type": "Synapse.DataFrame"
    },
    "708bb363-887f-45b7-bbac-7d05ddaf7e19": {
     "persist_state": {
      "view": {
       "chartOptions": {
        "aggregationType": "sum",
        "binsNumber": 10,
        "categoryFieldKeys": [],
        "chartType": "bar",
        "isStacked": false,
        "seriesFieldKeys": [],
        "wordFrequency": "-1"
       },
       "tableOptions": {},
       "type": "details",
       "viewOptionsGroup": [
        {
         "tabItems": [
          {
           "key": "0",
           "name": "Table",
           "options": {},
           "type": "table"
          }
         ]
        }
       ]
      }
     },
     "sync_state": {
      "isSummary": false,
      "language": "scala",
      "table": {
       "rows": [
        {
         "0": "1",
         "1": "test.connection",
         "2": "test/notebook-startup",
         "3": "published",
         "4": "2026-02-12T18:13:24.003773Z",
         "6": "{\"test\": true, \"timestamp\": \"2026-02-12T18:13:24.003745\", \"source\": \"parametric-insurance-notebook\", \"message\": \"Connect"
        },
        {
         "0": "1",
         "1": "test.connection",
         "2": "test/notebook-startup",
         "3": "published",
         "4": "2026-02-12T18:13:24.003773Z",
         "6": "{\"test\": true, \"timestamp\": \"2026-02-12T18:13:24.003745\", \"source\": \"parametric-insurance-notebook\", \"message\": \"Connect"
        },
        {
         "0": "2",
         "1": "outage.detected",
         "2": "outage/PRESTO-CA-20260212154437-8757",
         "3": "published",
         "4": "2026-02-12T18:18:47.947408Z",
         "6": "{\"event_id\": \"PRESTO-CA-20260212154437-8757\", \"utility_name\": \"Southern California Edison\", \"city\": \"San Francisco\", \"st"
        },
        {
         "0": "3",
         "1": "outage.detected",
         "2": "outage/PRESTO-CA-20260212165837-4029",
         "3": "published",
         "4": "2026-02-12T18:18:48.273161Z",
         "6": "{\"event_id\": \"PRESTO-CA-20260212165837-4029\", \"utility_name\": \"Southern California Edison\", \"city\": \"San Francisco\", \"st"
        },
        {
         "0": "4",
         "1": "claim.approved",
         "2": "claim/CLM-64C8F39E",
         "3": "published",
         "4": "2026-02-12T18:19:32.415269Z",
         "6": "{\"claim_id\": \"CLM-64C8F39E\", \"policy_id\": \"BI-007\", \"outage_event_id\": \"PRESTO-CA-20260212154437-8757\", \"status\": \"appro"
        },
        {
         "0": "5",
         "1": "claim.approved",
         "2": "claim/CLM-E3F9EE4F",
         "3": "published",
         "4": "2026-02-12T18:19:33.71446Z",
         "6": "{\"claim_id\": \"CLM-E3F9EE4F\", \"policy_id\": \"BI-007\", \"outage_event_id\": \"PRESTO-CA-20260212165837-4029\", \"status\": \"appro"
        },
        {
         "0": "6",
         "1": "claim.approved",
         "2": "claim/CLM-C5CF10A7",
         "3": "published",
         "4": "2026-02-12T18:27:44.953793Z",
         "6": "{\"claim_id\": \"CLM-C5CF10A7\", \"policy_id\": \"BI-007\", \"outage_event_id\": \"PRESTO-CA-20260212154437-8757\", \"status\": \"appro"
        },
        {
         "0": "7",
         "1": "claim.approved",
         "2": "claim/CLM-939B658F",
         "3": "published",
         "4": "2026-02-12T18:27:46.390965Z",
         "6": "{\"claim_id\": \"CLM-939B658F\", \"policy_id\": \"BI-007\", \"outage_event_id\": \"PRESTO-CA-20260212165837-4029\", \"status\": \"appro"
        },
        {
         "0": "8",
         "1": "claim.approved",
         "2": "claim/CLM-FD08689E",
         "3": "published",
         "4": "2026-02-12T18:29:30.857498Z",
         "6": "{\"claim_id\": \"CLM-FD08689E\", \"policy_id\": \"BI-007\", \"outage_event_id\": \"PRESTO-CA-20260212154437-8757\", \"status\": \"appro"
        },
        {
         "0": "9",
         "1": "claim.approved",
         "2": "claim/CLM-3A64B119",
         "3": "published",
         "4": "2026-02-12T18:29:37.873149Z",
         "6": "{\"claim_id\": \"CLM-3A64B119\", \"policy_id\": \"BI-007\", \"outage_event_id\": \"PRESTO-CA-20260212165837-4029\", \"status\": \"appro"
        },
        {
         "0": "10",
         "1": "claim.approved",
         "2": "claim/CLM-9B2902B6",
         "3": "published",
         "4": "2026-02-12T18:38:12.692621Z",
         "6": "{\"claim_id\": \"CLM-9B2902B6\", \"policy_id\": \"BI-007\", \"outage_event_id\": \"PRESTO-CA-20260212154437-8757\", \"status\": \"appro"
        },
        {
         "0": "11",
         "1": "claim.approved",
         "2": "claim/CLM-1AD74C52",
         "3": "published",
         "4": "2026-02-12T18:38:18.901785Z",
         "6": "{\"claim_id\": \"CLM-1AD74C52\", \"policy_id\": \"BI-007\", \"outage_event_id\": \"PRESTO-CA-20260212165837-4029\", \"status\": \"appro"
        },
        {
         "0": "12",
         "1": "payout.processed",
         "2": "payout/PAY-3805212B",
         "3": "published",
         "4": "2026-02-12T18:38:30.961083Z",
         "6": "{\"payout_id\": \"PAY-3805212B\", \"claim_id\": \"CLM-9B2902B6\", \"policy_id\": \"BI-007\", \"amount\": 50000.0, \"transaction_id\": \"T"
        },
        {
         "0": "13",
         "1": "payout.processed",
         "2": "payout/PAY-BABA66C1",
         "3": "published",
         "4": "2026-02-12T18:38:31.292163Z",
         "6": "{\"payout_id\": \"PAY-BABA66C1\", \"claim_id\": \"CLM-1AD74C52\", \"policy_id\": \"BI-007\", \"amount\": 3800.0, \"transaction_id\": \"TX"
        }
       ],
       "schema": [
        {
         "key": "0",
         "name": "sequence",
         "type": "int"
        },
        {
         "key": "1",
         "name": "event_type",
         "type": "string"
        },
        {
         "key": "2",
         "name": "subject",
         "type": "string"
        },
        {
         "key": "3",
         "name": "status",
         "type": "string"
        },
        {
         "key": "4",
         "name": "event_time",
         "type": "string"
        },
        {
         "key": "5",
         "name": "error",
         "type": "string"
        },
        {
         "key": "6",
         "name": "data_preview",
         "type": "string"
        }
       ],
       "truncated": false
      },
      "wranglerEntryContext": {
       "dataframeType": "pyspark"
      }
     },
     "type": "Synapse.DataFrame"
    },
    "d84a574d-ebc7-41bb-9b05-84415379fada": {
     "persist_state": {
      "view": {
       "chartOptions": {
        "aggregationType": "sum",
        "binsNumber": 10,
        "categoryFieldKeys": [],
        "chartType": "bar",
        "isStacked": false,
        "seriesFieldKeys": [],
        "wordFrequency": "-1"
       },
       "tableOptions": {},
       "type": "details",
       "viewOptionsGroup": [
        {
         "tabItems": [
          {
           "key": "0",
           "name": "Table",
           "options": {},
           "type": "table"
          }
         ]
        }
       ]
      }
     },
     "sync_state": {
      "isSummary": false,
      "language": "scala",
      "table": {
       "rows": [
        {
         "0": "PRESTO-CA-20260212154437-8757",
         "1": "Southern California Edison",
         "2": "San Francisco",
         "3": "CA",
         "4": "94111",
         "5": "15655",
         "6": "2026-02-12 15:44:37.771025",
         "7": "2026-02-12 18:18:37.771025",
         "8": "154",
         "9": "tree_contact",
         "10": "BI-007",
         "11": "Financial District Data Center",
         "12": "Data Center",
         "13": "30",
         "14": "2000.0",
         "15": "50000.0",
         "16": "124"
        },
        {
         "0": "PRESTO-CA-20260212165837-4029",
         "1": "Southern California Edison",
         "2": "San Francisco",
         "3": "CA",
         "4": "94111",
         "5": "1045",
         "6": "2026-02-12 16:58:37.771025",
         "7": "2026-02-12 18:25:37.771025",
         "8": "87",
         "9": "overload",
         "10": "BI-007",
         "11": "Financial District Data Center",
         "12": "Data Center",
         "13": "30",
         "14": "2000.0",
         "15": "50000.0",
         "16": "57"
        }
       ],
       "schema": [
        {
         "key": "0",
         "name": "event_id",
         "type": "string"
        },
        {
         "key": "1",
         "name": "utility_name",
         "type": "string"
        },
        {
         "key": "2",
         "name": "outage_city",
         "type": "string"
        },
        {
         "key": "3",
         "name": "outage_state",
         "type": "string"
        },
        {
         "key": "4",
         "name": "zip_code",
         "type": "string"
        },
        {
         "key": "5",
         "name": "affected_customers",
         "type": "int"
        },
        {
         "key": "6",
         "name": "outage_start",
         "type": "timestamp"
        },
        {
         "key": "7",
         "name": "outage_end",
         "type": "timestamp"
        },
        {
         "key": "8",
         "name": "duration_minutes",
         "type": "int"
        },
        {
         "key": "9",
         "name": "reported_cause",
         "type": "string"
        },
        {
         "key": "10",
         "name": "policy_id",
         "type": "string"
        },
        {
         "key": "11",
         "name": "business_name",
         "type": "string"
        },
        {
         "key": "12",
         "name": "business_type",
         "type": "string"
        },
        {
         "key": "13",
         "name": "threshold_minutes",
         "type": "int"
        },
        {
         "key": "14",
         "name": "hourly_rate",
         "type": "double"
        },
        {
         "key": "15",
         "name": "max_payout",
         "type": "double"
        },
        {
         "key": "16",
         "name": "excess_minutes",
         "type": "int"
        }
       ],
       "truncated": false
      },
      "wranglerEntryContext": {
       "candidateVariableNames": [
        "matched_df"
       ],
       "dataframeType": "pyspark"
      }
     },
     "type": "Synapse.DataFrame"
    },
    "e3beecd0-547d-4d3f-a314-aec6bdad5b12": {
     "persist_state": {
      "view": {
       "chartOptions": {
        "aggregationType": "sum",
        "binsNumber": 10,
        "categoryFieldKeys": [],
        "chartType": "bar",
        "isStacked": false,
        "seriesFieldKeys": [],
        "wordFrequency": "-1"
       },
       "tableOptions": {},
       "type": "details",
       "viewOptionsGroup": [
        {
         "tabItems": [
          {
           "key": "0",
           "name": "Table",
           "options": {},
           "type": "table"
          }
         ]
        }
       ]
      }
     },
     "sync_state": {
      "isSummary": false,
      "language": "scala",
      "table": {
       "rows": [
        {
         "0": "claim.approved",
         "1": "published",
         "2": "8"
        },
        {
         "0": "outage.detected",
         "1": "published",
         "2": "2"
        },
        {
         "0": "payout.processed",
         "1": "published",
         "2": "2"
        }
       ],
       "schema": [
        {
         "key": "0",
         "name": "event_type",
         "type": "string"
        },
        {
         "key": "1",
         "name": "status",
         "type": "string"
        },
        {
         "key": "2",
         "name": "event_count",
         "type": "bigint"
        }
       ],
       "truncated": false
      },
      "wranglerEntryContext": {
       "dataframeType": "pyspark"
      }
     },
     "type": "Synapse.DataFrame"
    },
    "f312b398-ad75-43f0-b999-4e7950d7201c": {
     "persist_state": {
      "view": {
       "chartOptions": {
        "aggregationType": "sum",
        "binsNumber": 10,
        "categoryFieldKeys": [],
        "chartType": "bar",
        "isStacked": false,
        "seriesFieldKeys": [],
        "wordFrequency": "-1"
       },
       "tableOptions": {},
       "type": "details",
       "viewOptionsGroup": [
        {
         "tabItems": [
          {
           "key": "0",
           "name": "Table",
           "options": {},
           "type": "table"
          }
         ]
        }
       ]
      }
     },
     "sync_state": {
      "isSummary": false,
      "language": "scala",
      "table": {
       "rows": [
        {
         "0": "CLM-9B2902B6",
         "1": "BI-007",
         "2": "Financial District Data Center",
         "3": "San Francisco",
         "4": "approved",
         "5": "50000.0",
         "6": "0.97",
         "7": "severe",
         "8": "1.5"
        },
        {
         "0": "CLM-C5CF10A7",
         "1": "BI-007",
         "2": "Financial District Data Center",
         "3": "San Francisco",
         "4": "approved",
         "5": "4960.0",
         "6": "0.97",
         "7": "high",
         "8": "1.2"
        },
        {
         "0": "CLM-FD08689E",
         "1": "BI-007",
         "2": "Financial District Data Center",
         "3": "San Francisco",
         "4": "approved",
         "5": "4960.0",
         "6": "0.97",
         "7": "high",
         "8": "1.2"
        },
        {
         "0": "CLM-64C8F39E",
         "1": "BI-007",
         "2": "Financial District Data Center",
         "3": "San Francisco",
         "4": "approved",
         "5": "4960.0",
         "6": "0.97",
         "7": "high",
         "8": "1.2"
        },
        {
         "0": "CLM-1AD74C52",
         "1": "BI-007",
         "2": "Financial District Data Center",
         "3": "San Francisco",
         "4": "approved",
         "5": "3800.0",
         "6": "0.95",
         "7": "severe",
         "8": "1.5"
        },
        {
         "0": "CLM-3A64B119",
         "1": "BI-007",
         "2": "Financial District Data Center",
         "3": "San Francisco",
         "4": "approved",
         "5": "2280.0",
         "6": "0.95",
         "7": "high",
         "8": "1.2"
        },
        {
         "0": "CLM-939B658F",
         "1": "BI-007",
         "2": "Financial District Data Center",
         "3": "San Francisco",
         "4": "approved",
         "5": "2280.0",
         "6": "0.95",
         "7": "high",
         "8": "1.2"
        },
        {
         "0": "CLM-E3F9EE4F",
         "1": "BI-007",
         "2": "Financial District Data Center",
         "3": "San Francisco",
         "4": "approved",
         "5": "2280.0",
         "6": "0.95",
         "7": "high",
         "8": "1.2"
        }
       ],
       "schema": [
        {
         "key": "0",
         "name": "claim_id",
         "type": "string"
        },
        {
         "key": "1",
         "name": "policy_id",
         "type": "string"
        },
        {
         "key": "2",
         "name": "business_name",
         "type": "string"
        },
        {
         "key": "3",
         "name": "city",
         "type": "string"
        },
        {
         "key": "4",
         "name": "status",
         "type": "string"
        },
        {
         "key": "5",
         "name": "payout_amount",
         "type": "double"
        },
        {
         "key": "6",
         "name": "ai_confidence_score",
         "type": "double"
        },
        {
         "key": "7",
         "name": "severity_assessment",
         "type": "string"
        },
        {
         "key": "8",
         "name": "weather_factor",
         "type": "double"
        }
       ],
       "truncated": false
      },
      "wranglerEntryContext": {
       "dataframeType": "pyspark"
      }
     },
     "type": "Synapse.DataFrame"
    }
   },
   "version": "0.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
