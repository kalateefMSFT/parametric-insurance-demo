{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0000001",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# WEATHER IMPACT EMAIL NOTIFIER\n",
    "# Parametric Insurance Demo â€” Notebook 4\n",
    "# ============================================================================\n",
    "#\n",
    "# Architecture:\n",
    "#   Event Grid (policy.weather.impact)\n",
    "#       â”‚\n",
    "#       â–¼\n",
    "#   [This notebook, triggered on schedule or manually]\n",
    "#       â”‚\n",
    "#       â–¼\n",
    "#   Orchestrator Agent (New Foundry â€” Responses API)\n",
    "#       â”‚  uses Fabric Data Agent as a tool\n",
    "#       â”‚  to query: policy details, prior claims, weather context\n",
    "#       â”‚\n",
    "#       â–¼\n",
    "#   Fabric Data Agent â†’ lakehouse SQL query â†’ structured context\n",
    "#       â”‚\n",
    "#       â–¼\n",
    "#   Orchestrator Agent composes professional email\n",
    "#       â”‚\n",
    "#       â–¼\n",
    "#   Email records saved to Delta table (email_notifications)\n",
    "#   [Optional] Send via Logic App webhook / SendGrid\n",
    "#\n",
    "# Prerequisites:\n",
    "#   - weather_alert_policy_impact.ipynb must have populated weather_impact_events\n",
    "#   - A Fabric Data Agent must be created in your workspace and connected\n",
    "#     to the parametric_insurance_lakehouse\n",
    "#   - An Orchestrator Agent (Foundry Responses API) must be created and\n",
    "#     configured with the Fabric Data Agent as a registered tool/action\n",
    "# ============================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-b0001",
   "metadata": {},
   "source": [
    "# ğŸ“§ Weather Impact Email Notifier\n",
    "\n",
    "```\n",
    "weather_impact_events (Delta)\n",
    "        â”‚\n",
    "        â–¼\n",
    "  Orchestrator Agent  â”€â”€â”€â”€ tool call â”€â”€â”€â”€â–º  Fabric Data Agent\n",
    "        â”‚                                        â”‚\n",
    "        â”‚                                  Lakehouse SQL query\n",
    "        â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€ enriched context â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "        â”‚\n",
    "   compose email\n",
    "        â”‚\n",
    "        â–¼\n",
    "  email_notifications (Delta) + [optional webhook send]\n",
    "```\n",
    "\n",
    "| Step | Description | Agent |\n",
    "|------|-------------|-------|\n",
    "| 0 | Config & imports | â€” |\n",
    "| 1 | Load unnotified impact events | Spark SQL |\n",
    "| 2 | Orchestrator queries Fabric Data Agent | **Orchestrator Agent** â†’ **Fabric Data Agent** |\n",
    "| 3 | Orchestrator composes professional email | **Orchestrator Agent** |\n",
    "| 4 | Persist emails to Delta | Spark |\n",
    "| 5 | [Optional] Dispatch via webhook | HTTP |\n",
    "| 6 | Mark impacts as notified | Delta merge |\n",
    "| 7 | Summary dashboard | Spark SQL |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-b0002",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ”§ Step 0 â€” Configuration & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0000002",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "%pip install azure-ai-projects==2.0.0b3 azure-core azure-ai-agents --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0000003",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import uuid\n",
    "import time\n",
    "import requests\n",
    "import warnings\n",
    "import textwrap\n",
    "import notebookutils\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any, Optional\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import (\n",
    "    StructType, StructField, StringType, TimestampType, BooleanType\n",
    ")\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# CONFIGURATION â€” Edit these values for your environment\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "@dataclass\n",
    "class EmailNotifierConfig:\n",
    "    \"\"\"Configuration for the weather impact email notifier.\"\"\"\n",
    "\n",
    "    # â”€â”€ Foundry / AI Project (New experience â€” Responses API) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # Endpoint format: https://<resource>.services.ai.azure.com/api/projects/<project>\n",
    "    foundry_endpoint:        str = \"<foundry-endpoint>\"\n",
    "\n",
    "    # The Orchestrator Agent is responsible for:\n",
    "    #   1. Calling the Fabric Data Agent to retrieve enriched policyholder context\n",
    "    #   2. Composing a professional email using that context\n",
    "    orchestrator_agent_id:   str = \"<orchestrator-agent-id>\"\n",
    "\n",
    "    # The Fabric Data Agent is connected to the parametric_insurance_lakehouse.\n",
    "    # It accepts natural-language questions and returns structured query results.\n",
    "    # Register it as a \"connected agent\" action inside the Orchestrator Agent.\n",
    "    fabric_data_agent_id:    str = \"<fabric-data-agent-id>\"\n",
    "\n",
    "    # â”€â”€ Processing limits â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # Maximum number of impact events to process in a single run.\n",
    "    # Set to a low number (3â€“5) for live demo; higher for batch processing.\n",
    "    max_events_per_run:      int = 10\n",
    "\n",
    "    # Only process impacts with a risk score at or above this threshold.\n",
    "    min_risk_score:          float = 0.3\n",
    "\n",
    "    # â”€â”€ Optional email dispatch â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # Leave blank to store emails in Delta only (no actual sending).\n",
    "    # Set to a Logic App / Power Automate HTTP trigger URL to send emails.\n",
    "    email_dispatch_webhook:  str = \"\"\n",
    "\n",
    "    # â”€â”€ Insurance company branding â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    insurer_name:            str = \"Parametric Shield Insurance\"\n",
    "    insurer_support_email:   str = \"support@parametricshield.com\"\n",
    "    insurer_support_phone:   str = \"1-800-555-0199\"\n",
    "    insurer_portal_url:      str = \"https://portal.parametricshield.com\"\n",
    "\n",
    "\n",
    "config = EmailNotifierConfig()\n",
    "\n",
    "# Override from Variable Library\n",
    "try:\n",
    "    env_lib = notebookutils.variableLibrary.getLibrary(\"environmentVariables\")\n",
    "    config.foundry_endpoint      = getattr(env_lib, \"FOUNDRY_ENDPOINT\",         config.foundry_endpoint)\n",
    "    config.orchestrator_agent_id = getattr(env_lib, \"ORCHESTRATOR_AGENT_ID\",    config.orchestrator_agent_id)\n",
    "    config.fabric_data_agent_id  = getattr(env_lib, \"FABRIC_DATA_AGENT_ID\",     config.fabric_data_agent_id)\n",
    "    config.email_dispatch_webhook= getattr(env_lib, \"EMAIL_DISPATCH_WEBHOOK\",   config.email_dispatch_webhook)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Widget overrides\n",
    "try:\n",
    "    config.foundry_endpoint      = config.foundry_endpoint      or notebookutils.mssparkutils.widgets.get(\"foundry_endpoint\")\n",
    "    config.orchestrator_agent_id = config.orchestrator_agent_id or notebookutils.mssparkutils.widgets.get(\"orchestrator_agent_id\")\n",
    "    config.fabric_data_agent_id  = config.fabric_data_agent_id  or notebookutils.mssparkutils.widgets.get(\"fabric_data_agent_id\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "FOUNDRY_ENABLED = bool(\n",
    "    config.foundry_endpoint and\n",
    "    config.orchestrator_agent_id and\n",
    "    config.foundry_endpoint != \"<foundry-endpoint>\"\n",
    ")\n",
    "\n",
    "FABRIC_DATA_AGENT_ENABLED = bool(\n",
    "    config.fabric_data_agent_id and\n",
    "    config.fabric_data_agent_id != \"<fabric-data-agent-id>\"\n",
    ")\n",
    "\n",
    "DISPATCH_ENABLED = bool(config.email_dispatch_webhook)\n",
    "\n",
    "spark    = SparkSession.builder.getOrCreate()\n",
    "RUN_ID   = uuid.uuid4().hex[:8].upper()\n",
    "now_utc  = datetime.now(timezone.utc).replace(tzinfo=None)\n",
    "\n",
    "print(\"ğŸ“§ Weather Impact Email Notifier\")\n",
    "print(f\"   Run ID:                {RUN_ID}\")\n",
    "print(f\"   Timestamp (UTC):       {now_utc.isoformat()}Z\")\n",
    "print(f\"   Foundry Agent:         {'âœ… ENABLED' if FOUNDRY_ENABLED else 'âš ï¸  DISABLED (template fallback)'}\")\n",
    "print(f\"   Fabric Data Agent:     {'âœ… ENABLED' if FABRIC_DATA_AGENT_ENABLED else 'âš ï¸  DISABLED (event data only)'}\")\n",
    "print(f\"   Email Dispatch:        {'âœ… ENABLED (webhook)' if DISPATCH_ENABLED else 'ğŸ“‹ LOCAL ONLY (Delta table)'}\")\n",
    "print(f\"   Max events/run:        {config.max_events_per_run}\")\n",
    "print(f\"   Min risk score:        {config.min_risk_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-b0003",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ—ï¸ Setup: Foundry Client + Email Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0000004",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Foundry AI Project Client (New Responses API)\n",
    "# ============================================================================\n",
    "\n",
    "os.environ[\"AZURE_CLIENT_ID\"]     = \"\"\n",
    "os.environ[\"AZURE_TENANT_ID\"]     = \"\"\n",
    "os.environ[\"AZURE_CLIENT_SECRET\"] = \"\"\n",
    "\n",
    "try:\n",
    "    env_lib = notebookutils.variableLibrary.getLibrary(\"environmentVariables\")\n",
    "    os.environ[\"AZURE_CLIENT_ID\"]     = env_lib.AZURE_CLIENT_ID\n",
    "    os.environ[\"AZURE_TENANT_ID\"]     = env_lib.AZURE_TENANT_ID\n",
    "    os.environ[\"AZURE_CLIENT_SECRET\"] = env_lib.AZURE_CLIENT_SECRET\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "foundry_client: Optional[AIProjectClient] = None\n",
    "orchestrator_agent = None\n",
    "\n",
    "if FOUNDRY_ENABLED:\n",
    "    try:\n",
    "        foundry_client = AIProjectClient(\n",
    "            endpoint   = config.foundry_endpoint,\n",
    "            credential = DefaultAzureCredential(),\n",
    "        )\n",
    "        # Retrieve the pre-configured Orchestrator Agent\n",
    "        orchestrator_agent = foundry_client.agents.get_agent(config.orchestrator_agent_id)\n",
    "        print(f\"âœ… Connected to Foundry. Orchestrator Agent: '{orchestrator_agent.name}'\")\n",
    "\n",
    "        if FABRIC_DATA_AGENT_ENABLED:\n",
    "            try:\n",
    "                fabric_agent = foundry_client.agents.get_agent(config.fabric_data_agent_id)\n",
    "                print(f\"âœ… Fabric Data Agent registered: '{fabric_agent.name}'\")\n",
    "                print(\"   The Orchestrator will call this agent as a tool to query the lakehouse.\")\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸  Fabric Data Agent not found by ID '{config.fabric_data_agent_id}': {e}\")\n",
    "                print(\"   Orchestrator will use event data only (no lakehouse enrichment).\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Could not initialise Foundry client: {e}\")\n",
    "        print(\"   Falling back to rule-based email template.\")\n",
    "        foundry_client = None\n",
    "else:\n",
    "    print(\"â„¹ï¸  Foundry not configured â€” will use built-in email template.\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Create email_notifications Delta table if it doesn't exist\n",
    "# ============================================================================\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS email_notifications (\n",
    "        notification_id   STRING,\n",
    "        run_id            STRING,\n",
    "        impact_id         STRING,\n",
    "        policy_id         STRING,\n",
    "        alert_id          STRING,\n",
    "        recipient_email   STRING,\n",
    "        recipient_name    STRING,\n",
    "        subject           STRING,\n",
    "        body_html         STRING,\n",
    "        body_text         STRING,\n",
    "        generation_method STRING,\n",
    "        dispatch_status   STRING,\n",
    "        dispatch_error    STRING,\n",
    "        created_at        TIMESTAMP,\n",
    "        dispatched_at     TIMESTAMP\n",
    "    ) USING DELTA\n",
    "\"\"\")\n",
    "\n",
    "print(\"âœ… email_notifications table ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-b0004",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“¥ Step 1 â€” Load Unnotified Impact Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0000005",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "print(\"ğŸ“¥ Loading unnotified weather impact events from lakehouse...\")\n",
    "\n",
    "try:\n",
    "    pending_df = spark.sql(f\"\"\"\n",
    "        SELECT *\n",
    "        FROM   weather_impact_events\n",
    "        WHERE  impact_status = 'pending_notification'\n",
    "          AND  risk_score   >= {config.min_risk_score}\n",
    "        ORDER BY risk_score DESC, created_at DESC\n",
    "        LIMIT  {config.max_events_per_run}\n",
    "    \"\"\")\n",
    "    pending = [row.asDict() for row in pending_df.collect()]\n",
    "    print(f\"  Pending impact events to process: {len(pending)}\")\n",
    "except Exception as e:\n",
    "    print(f\"  âŒ Could not query weather_impact_events: {e}\")\n",
    "    print(\"     Ensure weather_alert_policy_impact.ipynb has been run first.\")\n",
    "    pending = []\n",
    "\n",
    "if not pending:\n",
    "    print(\"\\nâ„¹ï¸  No pending impact events. Either:\")\n",
    "    print(\"   â€¢ Run weather_alert_policy_impact.ipynb first to populate impact events, or\")\n",
    "    print(\"   â€¢ All current events have already been notified.\")\n",
    "\n",
    "if pending:\n",
    "    display(pending_df.select(\n",
    "        \"impact_id\", \"policy_id\", \"business_name\", \"city\", \"state\",\n",
    "        \"alert_event\", \"alert_severity\", \"risk_score\", \"contact_email\"\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-b0005",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ¤– Steps 2â€“3 â€” Orchestrator Agent â†’ Fabric Data Agent â†’ Email Generation\n",
    "\n",
    "For each pending impact event, the **Orchestrator Agent** will:\n",
    "\n",
    "1. **Call the Fabric Data Agent** (as a registered tool/action) to retrieve enriched context:\n",
    "   - Full policy details, claim history, prior outages, current policy status\n",
    "2. **Compose a professional, personalised email** using that context plus the alert details\n",
    "\n",
    "If Foundry is not configured, a rule-based template is used instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0000006",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Helper: extract text from a Responses-API response object\n",
    "# ============================================================================\n",
    "\n",
    "def extract_response_text(response) -> str:\n",
    "    \"\"\"Pull plain text out of a Foundry Responses API response object.\"\"\"\n",
    "    text_parts = []\n",
    "    try:\n",
    "        for item in response.output:\n",
    "            if hasattr(item, \"content\"):\n",
    "                for block in item.content:\n",
    "                    if hasattr(block, \"text\"):\n",
    "                        text_parts.append(block.text)\n",
    "            elif hasattr(item, \"text\"):\n",
    "                text_parts.append(item.text)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return \"\\n\".join(text_parts).strip()\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Helper: rule-based email template (fallback when Foundry is unavailable)\n",
    "# ============================================================================\n",
    "\n",
    "def generate_template_email(imp: Dict[str, Any]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Generate a professional policy impact notification email from a\n",
    "    hard-coded template. Used as fallback when Foundry is not configured.\n",
    "    \"\"\"\n",
    "    onset_str   = imp.get(\"alert_onset\").strftime(\"%B %d, %Y at %I:%M %p UTC\") if imp.get(\"alert_onset\") else \"Immediately\"\n",
    "    expires_str = imp.get(\"alert_expires\").strftime(\"%B %d, %Y at %I:%M %p UTC\") if imp.get(\"alert_expires\") else \"Until further notice\"\n",
    "\n",
    "    subject = (\n",
    "        f\"[{config.insurer_name}] Weather Alert â€” {imp['alert_event']} \"\n",
    "        f\"near {imp['city']}, {imp['state']} | Policy {imp['policy_id']}\"\n",
    "    )\n",
    "\n",
    "    body_text = textwrap.dedent(f\"\"\"\n",
    "        Dear {imp['business_name']},\n",
    "\n",
    "        This is an important notification from {config.insurer_name} regarding your\n",
    "        Business Interruption Insurance policy ({imp['policy_id']}).\n",
    "\n",
    "        A {imp['alert_severity']} weather alert has been issued in your area that\n",
    "        may impact your business operations.\n",
    "\n",
    "        ALERT DETAILS\n",
    "        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        Alert Type:   {imp['alert_event']}\n",
    "        Severity:     {imp['alert_severity']}\n",
    "        Urgency:      {imp['alert_urgency']}\n",
    "        Affected Area:{imp['alert_area_desc']}\n",
    "        Onset:        {onset_str}\n",
    "        Expires:      {expires_str}\n",
    "        Distance:     Approximately {imp['distance_km']} km from your registered location\n",
    "\n",
    "        WHAT THIS MEANS FOR YOUR POLICY\n",
    "        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        Your policy is designed to respond automatically to qualifying power\n",
    "        outages. If this weather event causes an outage that exceeds your\n",
    "        threshold of {imp['threshold_minutes']} minutes, a claim will be\n",
    "        processed automatically â€” no action is required from you.\n",
    "\n",
    "        Your coverage summary:\n",
    "          â€¢ Policy ID:          {imp['policy_id']}\n",
    "          â€¢ Outage Threshold:   {imp['threshold_minutes']} minutes\n",
    "          â€¢ Hourly Rate:        ${imp['hourly_rate']:,.2f}/hour\n",
    "          â€¢ Maximum Payout:     ${imp['max_payout']:,.2f}\n",
    "\n",
    "        RECOMMENDED STEPS\n",
    "        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        1. Review the NWS alert at https://alerts.weather.gov\n",
    "        2. Ensure your contact information is current in our portal\n",
    "        3. Document any business disruptions for your records\n",
    "        4. Claims are processed automatically â€” no claim form needed\n",
    "\n",
    "        CONTACT US\n",
    "        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        Phone:  {config.insurer_support_phone}\n",
    "        Email:  {config.insurer_support_email}\n",
    "        Portal: {config.insurer_portal_url}\n",
    "\n",
    "        This notification was generated automatically based on active NWS\n",
    "        weather alerts and your registered policy location.\n",
    "\n",
    "        Sincerely,\n",
    "        {config.insurer_name} â€” Risk Monitoring Team\n",
    "    \"\"\").strip()\n",
    "\n",
    "    # Minimal HTML wrapper\n",
    "    body_html = (\n",
    "        \"<html><body style='font-family:Arial,sans-serif;max-width:680px;margin:auto;'>\"\n",
    "        + body_text.replace(\"\\n\", \"<br>\")\n",
    "        + \"</body></html>\"\n",
    "    )\n",
    "\n",
    "    return {\"subject\": subject, \"body_text\": body_text, \"body_html\": body_html}\n",
    "\n",
    "\n",
    "print(\"âœ… Email generation helpers ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0000007",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Core: Orchestrator Agent â†’ Fabric Data Agent â†’ Email\n",
    "# ============================================================================\n",
    "\n",
    "def call_orchestrator_for_email(imp: Dict[str, Any]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Invoke the Orchestrator Agent (Foundry Responses API).\n",
    "\n",
    "    The Orchestrator Agent's system prompt should instruct it to:\n",
    "      1. Call its registered Fabric Data Agent action with a natural-language\n",
    "         question to retrieve enriched policy/claim context from the lakehouse.\n",
    "      2. Use that context along with the provided alert + policy data to\n",
    "         draft a professional, empathetic, and accurate email notification.\n",
    "\n",
    "    Returns a dict with keys: subject, body_text, body_html\n",
    "    Falls back to generate_template_email() on any error.\n",
    "    \"\"\"\n",
    "    if not foundry_client or not orchestrator_agent:\n",
    "        return generate_template_email(imp)\n",
    "\n",
    "    onset_str   = imp.get(\"alert_onset\").isoformat()  if imp.get(\"alert_onset\")   else \"unknown\"\n",
    "    expires_str = imp.get(\"alert_expires\").isoformat() if imp.get(\"alert_expires\") else \"unknown\"\n",
    "\n",
    "    # â”€â”€ Prompt: give the Orchestrator all alert + policy facts, and ask it\n",
    "    # to call the Fabric Data Agent for enrichment before composing the email.\n",
    "    user_prompt = f\"\"\"\n",
    "You are an insurance operations AI for {config.insurer_name}.\n",
    "\n",
    "A severe weather alert has been detected near one of our policyholders.\n",
    "Your task:\n",
    "\n",
    "STEP 1 â€” DATA ENRICHMENT (use the Fabric Data Agent tool)\n",
    "Call the Fabric Data Agent to answer:\n",
    "\"For policy {imp['policy_id']} ({imp['business_name']}), provide:\n",
    "  - Full policy details (status, effective date, coverage)\n",
    "  - Number and outcome of prior claims in the last 12 months\n",
    "  - Any active claims or pending payouts\n",
    "  - The most recent outage event associated with this policy, if any\"\n",
    "\n",
    "STEP 2 â€” EMAIL COMPOSITION\n",
    "Using the enriched data from Step 1 PLUS the alert details below,\n",
    "compose a professional, clear, and empathetic email notification.\n",
    "\n",
    "The email must:\n",
    "  â€¢ Open with a warm but urgent subject line\n",
    "  â€¢ Acknowledge the specific weather threat in plain language\n",
    "  â€¢ Reference the policyholder by business name\n",
    "  â€¢ Explain exactly what triggers their parametric coverage\n",
    "  â€¢ Personalise based on their claim history (if any prior claims: reassure;\n",
    "    if first potential event: explain the automatic process clearly)\n",
    "  â€¢ List 3â€“4 recommended preparation steps specific to the alert type\n",
    "  â€¢ Close with contact information and a confident, supportive tone\n",
    "  â€¢ NOT promise a specific payout â€” only explain the coverage mechanism\n",
    "\n",
    "ALERT DETAILS:\n",
    "  Alert Type:    {imp['alert_event']}\n",
    "  Severity:      {imp['alert_severity']} | Urgency: {imp['alert_urgency']} | Certainty: {imp.get('alert_certainty','Unknown')}\n",
    "  Headline:      {imp.get('alert_headline', '')}\n",
    "  Affected Area: {imp.get('alert_area_desc', '')}\n",
    "  Onset:         {onset_str}\n",
    "  Expires:       {expires_str}\n",
    "\n",
    "POLICYHOLDER DETAILS (from weather impact event):\n",
    "  Policy ID:         {imp['policy_id']}\n",
    "  Business Name:     {imp['business_name']}\n",
    "  Business Type:     {imp['business_type']}\n",
    "  City, State:       {imp['city']}, {imp['state']}\n",
    "  Contact Email:     {imp['contact_email']}\n",
    "  Outage Threshold:  {imp['threshold_minutes']} minutes\n",
    "  Hourly Rate:       ${imp['hourly_rate']:,.2f}/hour\n",
    "  Max Payout:        ${imp['max_payout']:,.2f}\n",
    "  Distance from alert centroid: {imp['distance_km']} km\n",
    "  Risk Score:        {imp['risk_score']} (0â€“1 scale)\n",
    "\n",
    "INSURER CONTACT INFO:\n",
    "  Name:    {config.insurer_name}\n",
    "  Support: {config.insurer_support_phone} | {config.insurer_support_email}\n",
    "  Portal:  {config.insurer_portal_url}\n",
    "\n",
    "OUTPUT FORMAT â€” return a JSON object with exactly these keys:\n",
    "{{\n",
    "  \"subject\": \"<email subject line>\",\n",
    "  \"body_text\": \"<plain-text email body>\",\n",
    "  \"body_html\": \"<HTML email body with inline styles, no external CSS>\"\n",
    "}}\n",
    "\n",
    "Return ONLY the JSON object. No markdown fences, no preamble.\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = foundry_client.agents.responses.create(\n",
    "            agent_id = config.orchestrator_agent_id,\n",
    "            input    = [{\"role\": \"user\", \"content\": user_prompt}],\n",
    "            # The Orchestrator Agent must have the Fabric Data Agent registered\n",
    "            # as a connected agent action in the Foundry portal for tool-calling\n",
    "            # to work. The SDK will handle the tool_call / tool_result round-trip\n",
    "            # automatically when the agent decides to call it.\n",
    "        )\n",
    "\n",
    "        raw_text = extract_response_text(response).strip()\n",
    "\n",
    "        if not raw_text:\n",
    "            print(f\"  âš ï¸  No text in Orchestrator response â€” using template\")\n",
    "            return generate_template_email(imp)\n",
    "\n",
    "        # Strip markdown code fences if present\n",
    "        if raw_text.startswith(\"```\"):\n",
    "            raw_text = raw_text.split(\"\\n\", 1)[1].rsplit(\"```\", 1)[0].strip()\n",
    "\n",
    "        parsed = json.loads(raw_text)\n",
    "\n",
    "        # Validate required keys\n",
    "        for key in (\"subject\", \"body_text\", \"body_html\"):\n",
    "            if key not in parsed:\n",
    "                raise ValueError(f\"Missing key '{key}' in agent response\")\n",
    "\n",
    "        print(f\"  âœ… Orchestrator generated email for {imp['business_name']}\")\n",
    "        return parsed\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"  âš ï¸  JSON parse error ({imp['policy_id']}): {e} â€” using template\")\n",
    "        return generate_template_email(imp)\n",
    "    except Exception as e:\n",
    "        print(f\"  âš ï¸  Orchestrator error ({imp['policy_id']}): {e} â€” using template\")\n",
    "        return generate_template_email(imp)\n",
    "\n",
    "\n",
    "print(\"âœ… Orchestrator call function ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0000008",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Main loop: process each pending impact event\n",
    "# ============================================================================\n",
    "\n",
    "if not pending:\n",
    "    print(\"â„¹ï¸  No pending impact events to process. Skipping email generation.\")\n",
    "else:\n",
    "    print(f\"ğŸ¤– Processing {len(pending)} impact event(s)...\")\n",
    "    print(f\"   Using: {'Orchestrator â†’ Fabric Data Agent' if FOUNDRY_ENABLED and FABRIC_DATA_AGENT_ENABLED else 'Orchestrator Agent only' if FOUNDRY_ENABLED else 'Rule-based template'}\\n\")\n",
    "\n",
    "    notification_records: List[Dict[str, Any]] = []\n",
    "\n",
    "    for i, imp in enumerate(pending, 1):\n",
    "        print(f\"[{i}/{len(pending)}] {imp['business_name']} ({imp['city']}, {imp['state']}) â€” {imp['alert_event']}\")\n",
    "\n",
    "        email = call_orchestrator_for_email(imp)\n",
    "        generation_method = (\n",
    "            \"orchestrator+fabric_data_agent\" if FOUNDRY_ENABLED and FABRIC_DATA_AGENT_ENABLED\n",
    "            else \"orchestrator_agent\" if FOUNDRY_ENABLED\n",
    "            else \"rule_based_template\"\n",
    "        )\n",
    "\n",
    "        notification_records.append({\n",
    "            \"notification_id\":   f\"NOTIF-{RUN_ID}-{uuid.uuid4().hex[:6].upper()}\",\n",
    "            \"run_id\":            RUN_ID,\n",
    "            \"impact_id\":         imp[\"impact_id\"],\n",
    "            \"policy_id\":         imp[\"policy_id\"],\n",
    "            \"alert_id\":          imp[\"alert_id\"],\n",
    "            \"recipient_email\":   imp[\"contact_email\"],\n",
    "            \"recipient_name\":    imp[\"business_name\"],\n",
    "            \"subject\":           email[\"subject\"],\n",
    "            \"body_html\":         email[\"body_html\"],\n",
    "            \"body_text\":         email[\"body_text\"],\n",
    "            \"generation_method\": generation_method,\n",
    "            \"dispatch_status\":   \"pending\",\n",
    "            \"dispatch_error\":    None,\n",
    "            \"created_at\":        now_utc,\n",
    "            \"dispatched_at\":     None,\n",
    "        })\n",
    "\n",
    "        # Brief pause to avoid rate-limiting on the Foundry endpoint\n",
    "        if FOUNDRY_ENABLED and i < len(pending):\n",
    "            time.sleep(1)\n",
    "\n",
    "    print(f\"\\n  âœ… Generated {len(notification_records)} email(s).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-b0006",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ’¾ Step 4 â€” Persist Emails to Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0000009",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "if not pending:\n",
    "    print(\"â„¹ï¸  Nothing to save.\")\n",
    "else:\n",
    "    notif_schema = StructType([\n",
    "        StructField(\"notification_id\",   StringType()),\n",
    "        StructField(\"run_id\",            StringType()),\n",
    "        StructField(\"impact_id\",         StringType()),\n",
    "        StructField(\"policy_id\",         StringType()),\n",
    "        StructField(\"alert_id\",          StringType()),\n",
    "        StructField(\"recipient_email\",   StringType()),\n",
    "        StructField(\"recipient_name\",    StringType()),\n",
    "        StructField(\"subject\",           StringType()),\n",
    "        StructField(\"body_html\",         StringType()),\n",
    "        StructField(\"body_text\",         StringType()),\n",
    "        StructField(\"generation_method\", StringType()),\n",
    "        StructField(\"dispatch_status\",   StringType()),\n",
    "        StructField(\"dispatch_error\",    StringType()),\n",
    "        StructField(\"created_at\",        TimestampType()),\n",
    "        StructField(\"dispatched_at\",     TimestampType()),\n",
    "    ])\n",
    "\n",
    "    notif_df = spark.createDataFrame(notification_records, schema=notif_schema)\n",
    "    notif_df.write.format(\"delta\").mode(\"append\").saveAsTable(\"email_notifications\")\n",
    "    print(f\"âœ… Saved {len(notification_records)} email record(s) to Delta table: email_notifications\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-b0007",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸš€ Step 5 â€” [Optional] Dispatch Emails via Webhook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0000010",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Optional: POST email payloads to a Logic App / Power Automate webhook\n",
    "# or any HTTP endpoint that accepts JSON and dispatches emails.\n",
    "#\n",
    "# Expected webhook payload shape:\n",
    "#   {\n",
    "#     \"to\":      \"recipient@example.com\",\n",
    "#     \"subject\": \"...\",\n",
    "#     \"html\":    \"<html>...\",\n",
    "#     \"text\":    \"...\",\n",
    "#     \"from\":    \"noreply@parametricshield.com\",\n",
    "#     \"metadata\": { \"notification_id\": \"...\", \"policy_id\": \"...\", \"impact_id\": \"...\" }\n",
    "#   }\n",
    "# ============================================================================\n",
    "\n",
    "if not pending:\n",
    "    print(\"â„¹ï¸  Nothing to dispatch.\")\n",
    "elif not DISPATCH_ENABLED:\n",
    "    print(\"â„¹ï¸  Email dispatch webhook not configured.\")\n",
    "    print(\"   Set config.email_dispatch_webhook to a Logic App / Power Automate URL to send emails.\")\n",
    "    print(\"   Emails are saved to the email_notifications Delta table for review.\")\n",
    "else:\n",
    "    print(f\"ğŸš€ Dispatching {len(notification_records)} email(s) via webhook...\\n\")\n",
    "    dispatched, dispatch_failed = 0, 0\n",
    "\n",
    "    for notif in notification_records:\n",
    "        payload = {\n",
    "            \"to\":      notif[\"recipient_email\"],\n",
    "            \"subject\": notif[\"subject\"],\n",
    "            \"html\":    notif[\"body_html\"],\n",
    "            \"text\":    notif[\"body_text\"],\n",
    "            \"from\":    f\"noreply@{config.insurer_support_email.split('@')[1]}\",\n",
    "            \"metadata\": {\n",
    "                \"notification_id\": notif[\"notification_id\"],\n",
    "                \"policy_id\":       notif[\"policy_id\"],\n",
    "                \"impact_id\":       notif[\"impact_id\"],\n",
    "                \"run_id\":          notif[\"run_id\"],\n",
    "            }\n",
    "        }\n",
    "        try:\n",
    "            resp = requests.post(\n",
    "                config.email_dispatch_webhook,\n",
    "                json=payload,\n",
    "                timeout=15,\n",
    "            )\n",
    "            resp.raise_for_status()\n",
    "            notif[\"dispatch_status\"] = \"dispatched\"\n",
    "            notif[\"dispatched_at\"]   = datetime.now(timezone.utc).replace(tzinfo=None)\n",
    "            dispatched += 1\n",
    "            print(f\"  âœ… Dispatched â†’ {notif['recipient_email']} ({notif['policy_id']})\")\n",
    "        except Exception as e:\n",
    "            notif[\"dispatch_status\"] = \"failed\"\n",
    "            notif[\"dispatch_error\"]  = str(e)[:500]\n",
    "            dispatch_failed += 1\n",
    "            print(f\"  âŒ Failed    â†’ {notif['recipient_email']} ({notif['policy_id']}): {e}\")\n",
    "\n",
    "    print(f\"\\n  Dispatched: {dispatched}  |  Failed: {dispatch_failed}\")\n",
    "\n",
    "    # Update dispatch status in Delta\n",
    "    if dispatched or dispatch_failed:\n",
    "        update_schema = StructType([\n",
    "            StructField(\"notification_id\", StringType()),\n",
    "            StructField(\"dispatch_status\", StringType()),\n",
    "            StructField(\"dispatch_error\",  StringType()),\n",
    "            StructField(\"dispatched_at\",   TimestampType()),\n",
    "        ])\n",
    "        update_df = spark.createDataFrame(\n",
    "            [{\"notification_id\": n[\"notification_id\"],\n",
    "              \"dispatch_status\": n[\"dispatch_status\"],\n",
    "              \"dispatch_error\":  n.get(\"dispatch_error\"),\n",
    "              \"dispatched_at\":   n.get(\"dispatched_at\")} for n in notification_records],\n",
    "            schema=update_schema,\n",
    "        )\n",
    "        update_df.createOrReplaceTempView(\"dispatch_updates\")\n",
    "        spark.sql(\"\"\"\n",
    "            MERGE INTO email_notifications AS target\n",
    "            USING dispatch_updates AS source\n",
    "            ON target.notification_id = source.notification_id\n",
    "            WHEN MATCHED THEN UPDATE SET\n",
    "                target.dispatch_status = source.dispatch_status,\n",
    "                target.dispatch_error  = source.dispatch_error,\n",
    "                target.dispatched_at   = source.dispatched_at\n",
    "        \"\"\")\n",
    "        print(\"âœ… Dispatch status updated in email_notifications.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-b0008",
   "metadata": {},
   "source": [
    "---\n",
    "## âœ… Step 6 â€” Mark Impact Events as Notified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0000011",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "if not pending:\n",
    "    print(\"â„¹ï¸  Nothing to mark.\")\n",
    "else:\n",
    "    processed_impact_ids = [imp[\"impact_id\"] for imp in pending]\n",
    "    ids_literal = \", \".join(f\"'{iid}'\" for iid in processed_impact_ids)\n",
    "\n",
    "    try:\n",
    "        spark.sql(f\"\"\"\n",
    "            UPDATE weather_impact_events\n",
    "            SET    impact_status = 'notified'\n",
    "            WHERE  impact_id IN ({ids_literal})\n",
    "        \"\"\")\n",
    "        print(f\"âœ… Marked {len(processed_impact_ids)} impact event(s) as 'notified' in weather_impact_events.\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Could not update impact_status: {e}\")\n",
    "        print(\"   Impact events remain in 'pending_notification' status â€” they will be reprocessed next run.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-b0009",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“Š Step 7 â€” Summary Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0000012",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(f\"RUN SUMMARY â€” Run ID: {RUN_ID}\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"  Email generation: {'Orchestrator + Fabric Data Agent' if FOUNDRY_ENABLED and FABRIC_DATA_AGENT_ENABLED else 'Orchestrator Agent' if FOUNDRY_ENABLED else 'Rule-based template'}\")\n",
    "print(f\"  Impact events processed: {len(pending)}\")\n",
    "\n",
    "if pending:\n",
    "    gen_counts = {}\n",
    "    for n in notification_records:\n",
    "        m = n[\"generation_method\"]\n",
    "        gen_counts[m] = gen_counts.get(m, 0) + 1\n",
    "    for method, cnt in gen_counts.items():\n",
    "        print(f\"  Generated via {method}: {cnt}\")\n",
    "\n",
    "print()\n",
    "print(\"--- Email Notifications (This Run) ---\")\n",
    "try:\n",
    "    display(spark.sql(f\"\"\"\n",
    "        SELECT\n",
    "            notification_id,\n",
    "            policy_id,\n",
    "            recipient_name,\n",
    "            recipient_email,\n",
    "            subject,\n",
    "            generation_method,\n",
    "            dispatch_status,\n",
    "            created_at\n",
    "        FROM email_notifications\n",
    "        WHERE run_id = '{RUN_ID}'\n",
    "        ORDER BY created_at\n",
    "    \"\"\"))\n",
    "except Exception as e:\n",
    "    print(f\"  Could not display table: {e}\")\n",
    "\n",
    "print()\n",
    "print(\"--- Email Notifications (All Time) ---\")\n",
    "try:\n",
    "    display(spark.sql(\"\"\"\n",
    "        SELECT\n",
    "            generation_method,\n",
    "            dispatch_status,\n",
    "            COUNT(*) AS total,\n",
    "            MIN(created_at) AS first_sent,\n",
    "            MAX(created_at) AS last_sent\n",
    "        FROM email_notifications\n",
    "        GROUP BY generation_method, dispatch_status\n",
    "        ORDER BY total DESC\n",
    "    \"\"\"))\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print()\n",
    "print(\"--- Sample Email Preview (most recent) ---\")\n",
    "try:\n",
    "    sample = spark.sql(\"\"\"\n",
    "        SELECT subject, body_text\n",
    "        FROM   email_notifications\n",
    "        ORDER BY created_at DESC\n",
    "        LIMIT  1\n",
    "    \"\"\").collect()\n",
    "    if sample:\n",
    "        print(f\"\\nSUBJECT: {sample[0]['subject']}\\n\")\n",
    "        # Print first 60 lines of the body\n",
    "        body_lines = (sample[0]['body_text'] or \"\").split(\"\\n\")\n",
    "        for line in body_lines[:60]:\n",
    "            print(line)\n",
    "        if len(body_lines) > 60:\n",
    "            print(f\"... [{len(body_lines) - 60} more lines]\")\n",
    "except Exception as e:\n",
    "    print(f\"  Could not preview email: {e}\")\n",
    "\n",
    "# Refresh SQL Endpoint\n",
    "access_token = mssparkutils.credentials.getToken(\"https://api.fabric.microsoft.com/\")\n",
    "\n",
    "# Fabric REST API endpoint for refreshing SQL endpoint metadata\n",
    "workspace_id = \"c244c53e-58d3-4055-8dc8-8c79bc0ad4b0\"\n",
    "lakehouse_id = \"5166d063-e222-49b7-948b-f029f463cc2b\"\n",
    "refresh_url = f\"https://api.fabric.microsoft.com/v1/workspaces/{workspace_id}/lakehouses/{lakehouse_id}/refreshSqlEndpoint\"\n",
    "\n",
    "# === CALL THE REFRESH API ===\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {access_token}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = requests.post(refresh_url, headers=headers)\n",
    "    if response.status_code == 202:\n",
    "        print(\"âœ… SQL Endpoint refresh triggered successfully.\")\n",
    "    else:\n",
    "        print(f\"âš ï¸ Failed to refresh SQL Endpoint. Status: {response.status_code}\")\n",
    "        print(response.text)\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error calling refresh API: {e}\")\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"âœ… Notebook complete.\")\n",
    "print(\"   ğŸ“‹ Emails are stored in the email_notifications Delta table.\")\n",
    "print(\"   ğŸš€ To send emails, configure config.email_dispatch_webhook with a Logic App URL.\")"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "notebook_environment": {},
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "save_output": true,
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.dynamicAllocation.enabled": "false"
    },
    "enableDebugMode": false
   }
  },
  "synapse_widget": {
   "state": {},
   "version": "0.1"
  },
  "widgets": {}
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
