{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000001",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# WEATHER IMPACT EMAIL NOTIFIER\n",
    "# Parametric Insurance Demo â€” Notebook 4\n",
    "# ============================================================================\n",
    "#\n",
    "# Architecture (two-step agent pattern):\n",
    "#\n",
    "#   Fabric Notebook (this file)\n",
    "#       â”‚\n",
    "#       â”œâ”€â”€ Step A: Call Spark / SQL query (native)\n",
    "#       â”‚\n",
    "#       â””â”€â”€ Step B: Call Orchestrator Agent via Foundry Responses API\n",
    "#                   (LLM only â€” enriched context + alert â†’ professional email)\n",
    "#\n",
    "# Why this pattern?\n",
    "#   Fabric Data Agents currently cannot be invoked as a tool by another\n",
    "#   agent when the caller is a Fabric notebook session. Instead, the\n",
    "#   notebook calls the Spark / SQL query (native), then passes the enriched\n",
    "#   context to the Orchestrator Agent for email composition.\n",
    "#\n",
    "# Prerequisites:\n",
    "#   - weather_alert_policy_impact.ipynb must have populated weather_impact_events\n",
    "#   - An Orchestrator Agent (Foundry Responses API) must be created\n",
    "#     (LLM-only â€” no tools/actions needed)\n",
    "# ============================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000002",
   "metadata": {},
   "source": [
    "# ğŸ“§ Weather Impact Email Notifier\n",
    "\n",
    "```\n",
    "weather_impact_events (Delta)\n",
    "        â”‚\n",
    "        â–¼\n",
    "  Fabric Notebook\n",
    "        â”‚\n",
    "        â”œâ”€â”€â–º Lakehouse SQL query\n",
    "        â”‚         â”‚\n",
    "        â”‚â—„â”€â”€ enriched context â”€â”€â”˜\n",
    "        â”‚\n",
    "        â”œâ”€â”€â–º Orchestrator Agent (Foundry Responses API, LLM only)\n",
    "        â”‚         â”‚\n",
    "        â”‚    compose email using enriched context\n",
    "        â”‚         â”‚\n",
    "        â”‚â—„â”€â”€ email JSON â”€â”€â”˜\n",
    "        â”‚\n",
    "        â–¼\n",
    "  email_notifications (Delta) + [optional webhook send]\n",
    "```\n",
    "\n",
    "| Step | Description | Component |\n",
    "|------|-------------|----------|\n",
    "| 0 | Config & imports | â€” |\n",
    "| 1 | Load unnotified impact events | Spark SQL |\n",
    "| 2 | Issue Spark / SQL query (native) |\n",
    "| 3 | Call Orchestrator Agent to compose email | **Orchestrator Agent** (Responses API) |\n",
    "| 4 | Persist emails to Delta | Spark |\n",
    "| 5 | [Optional] Dispatch via webhook | HTTP |\n",
    "| 6 | Mark impacts as notified | Delta merge |\n",
    "| 7 | Summary dashboard | Spark SQL |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000003",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ”§ Step 0 â€” Configuration & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000004",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "%pip install azure-ai-projects==2.0.0b3 azure-core --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000005",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import uuid\n",
    "import time\n",
    "import requests\n",
    "import warnings\n",
    "import textwrap\n",
    "import notebookutils\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any, Optional\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import (\n",
    "    StructType, StructField, StringType, TimestampType, BooleanType\n",
    ")\n",
    "\n",
    "# Foundry Responses API â€” for the Orchestrator Agent (LLM only)\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.identity import ClientSecretCredential\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "env_lib = notebookutils.variableLibrary.getLibrary(\"environmentVariables\")\n",
    "os.environ[\"AZURE_CLIENT_ID\"]     = env_lib.AZURE_CLIENT_ID\n",
    "os.environ[\"AZURE_TENANT_ID\"]     = env_lib.AZURE_TENANT_ID\n",
    "os.environ[\"AZURE_CLIENT_SECRET\"] = env_lib.AZURE_CLIENT_SECRET\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# CONFIGURATION â€” Edit these values for your environment\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "@dataclass\n",
    "class EmailNotifierConfig:\n",
    "    \"\"\"Configuration for the weather impact email notifier.\"\"\"\n",
    "\n",
    "    # â”€â”€ Foundry / AI Project (New experience â€” Responses API) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    foundry_endpoint = env_lib.FOUNDRY_ENDPOINT\n",
    "\n",
    "    # The Orchestrator Agent composes professional emails.\n",
    "    # LLM-only agent (no tools) â€” notebook provides all context in the prompt.\n",
    "    orchestrator_agent = env_lib.ORCHESTRATOR_AGENT\n",
    "\n",
    "    # â”€â”€ Processing limits â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    max_events_per_run:      int = 10\n",
    "    min_risk_score:          float = 0.3\n",
    "\n",
    "    # â”€â”€ Optional email dispatch â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    email_dispatch_webhook:  str = \"\"\n",
    "\n",
    "    # â”€â”€ Insurance company branding â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    insurer_name:            str = \"Parametric Shield Insurance\"\n",
    "    insurer_support_email:   str = \"support@parametricshield.com\"\n",
    "    insurer_support_phone:   str = \"1-800-555-0199\"\n",
    "    insurer_portal_url:      str = \"https://portal.parametricshield.com\"\n",
    "\n",
    "\n",
    "config = EmailNotifierConfig()\n",
    "\n",
    "FOUNDRY_ENABLED = bool(\n",
    "    config.foundry_endpoint and\n",
    "    config.orchestrator_agent\n",
    ")\n",
    "\n",
    "DISPATCH_ENABLED = bool(config.email_dispatch_webhook)\n",
    "\n",
    "spark    = SparkSession.builder.getOrCreate()\n",
    "RUN_ID   = uuid.uuid4().hex[:8].upper()\n",
    "now_utc  = datetime.now(timezone.utc).replace(tzinfo=None)\n",
    "\n",
    "print(\"ğŸ“§ Weather Impact Email Notifier\")\n",
    "print(f\"   Run ID:                {RUN_ID}\")\n",
    "print(f\"   Timestamp (UTC):       {now_utc.isoformat()}Z\")\n",
    "print(f\"   Foundry Agent:         {'âœ… ENABLED' if FOUNDRY_ENABLED else 'âš ï¸  DISABLED (template fallback)'}\")\n",
    "print(f\"   Email Dispatch:        {'âœ… ENABLED (webhook)' if DISPATCH_ENABLED else 'ğŸ“‹ LOCAL ONLY (Delta table)'}\")\n",
    "print(f\"   Max events/run:        {config.max_events_per_run}\")\n",
    "print(f\"   Min risk score:        {config.min_risk_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000006",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ—ï¸ Setup: PolicyEmailOrchestrator + Email Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000007",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Policy Orchestrator Class\n",
    "# ============================================================================\n",
    "\n",
    "class PolicyEmailOrchestrator:\n",
    "    \"\"\"\n",
    "    Fabric-native orchestration:\n",
    "      1) Query Fabric Lakehouse tables\n",
    "      2) Inject enrichment into prompt\n",
    "      3) Call Foundry Orchestrator Agent\n",
    "      4) Validate structured email output\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        foundry_endpoint: str,\n",
    "        tenant_id: str,\n",
    "        client_id: str,\n",
    "        client_secret: str,\n",
    "        orchestrator_agent_name: str,\n",
    "        insurer_config,\n",
    "    ):\n",
    "        self.agent_name = orchestrator_agent_name\n",
    "        self.config = insurer_config\n",
    "\n",
    "        credential = ClientSecretCredential(\n",
    "            tenant_id=tenant_id,\n",
    "            client_id=client_id,\n",
    "            client_secret=client_secret,\n",
    "        )\n",
    "\n",
    "        self.project_client = AIProjectClient(\n",
    "            endpoint=foundry_endpoint,\n",
    "            credential=credential,\n",
    "        )\n",
    "\n",
    "        self.openai_client = self.project_client.get_openai_client()\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Step 1 â€” Fabric enrichment\n",
    "    # ------------------------------------------------------------\n",
    "    def get_policy_context(self, policy_id: str) -> dict:\n",
    "        df = spark.sql(f\"\"\"\n",
    "            SELECT *\n",
    "            FROM policies\n",
    "            WHERE policy_id = '{policy_id}'\n",
    "            LIMIT 1\n",
    "        \"\"\")\n",
    "\n",
    "        row = df.toPandas().iloc[0].dropna().to_dict()\n",
    "        clean = {k: (v.isoformat() if hasattr(v, \"isoformat\") else v)\n",
    "                 for k, v in row.items()}\n",
    "\n",
    "        return json.loads(json.dumps(clean, default=str))\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Step 2 â€” Prompt builder\n",
    "    # ------------------------------------------------------------\n",
    "    def _build_prompt(\n",
    "        self,\n",
    "        imp: Dict[str, Any],\n",
    "        enrichment: Dict[str, Any],\n",
    "    ) -> str:\n",
    "\n",
    "        onset = imp.get(\"alert_onset\")\n",
    "        expires = imp.get(\"alert_expires\")\n",
    "\n",
    "        enriched_json = json.dumps(enrichment, indent=2)\n",
    "\n",
    "        return f\"\"\"You are an insurance operations AI for {config.insurer_name}.\n",
    "\n",
    "                A severe weather alert has been detected near one of our policyholders.\n",
    "                Using the ENRICHED CONTEXT below (retrieved from our data systems) plus the\n",
    "                ALERT DETAILS and POLICYHOLDER DETAILS, compose a professional, clear, and\n",
    "                empathetic email notification.\n",
    "\n",
    "                ENRICHED CONTEXT FROM DATA SYSTEMS:\n",
    "                â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "                {enriched_json}\n",
    "                â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "                The email must:\n",
    "                  â€¢ Open with a warm but urgent subject line\n",
    "                  â€¢ Acknowledge the specific weather threat in plain language\n",
    "                  â€¢ Reference the policyholder by business name\n",
    "                  â€¢ Explain exactly what triggers their parametric coverage\n",
    "                  â€¢ Personalise based on their claim history (if any prior claims: reassure;\n",
    "                    if first potential event: explain the automatic process clearly)\n",
    "                  â€¢ List 3â€“4 recommended preparation steps specific to the alert type\n",
    "                  â€¢ Close with contact information and a confident, supportive tone\n",
    "                  â€¢ NOT promise a specific payout â€” only explain the coverage mechanism\n",
    "\n",
    "                ALERT DETAILS:\n",
    "                  Alert Type:    {imp['alert_event']}\n",
    "                  Severity:      {imp['alert_severity']} | Urgency: {imp['alert_urgency']} | Certainty: {imp.get('alert_certainty','Unknown')}\n",
    "                  Headline:      {imp.get('alert_headline', '')}\n",
    "                  Affected Area: {imp.get('alert_area_desc', '')}\n",
    "                  Onset:         {onset}\n",
    "                  Expires:       {expires}\n",
    "\n",
    "                POLICYHOLDER DETAILS (from weather impact event):\n",
    "                  Policy ID:         {imp['policy_id']}\n",
    "                  Business Name:     {imp['business_name']}\n",
    "                  Business Type:     {imp['business_type']}\n",
    "                  City, State:       {imp['city']}, {imp['state']}\n",
    "                  Contact Email:     {imp['contact_email']}\n",
    "                  Outage Threshold:  {imp['threshold_minutes']} minutes\n",
    "                  Hourly Rate:       ${imp['hourly_rate']:,.2f}/hour\n",
    "                  Max Payout:        ${imp['max_payout']:,.2f}\n",
    "                  Distance from alert centroid: {imp['distance_km']} km\n",
    "                  Risk Score:        {imp['risk_score']} (0â€“1 scale)\n",
    "\n",
    "                INSURER CONTACT INFO:\n",
    "                  Name:    {config.insurer_name}\n",
    "                  Support: {config.insurer_support_phone} | {config.insurer_support_email}\n",
    "                  Portal:  {config.insurer_portal_url}\n",
    "\n",
    "                OUTPUT FORMAT â€” return a JSON object with exactly these keys:\n",
    "                {{\n",
    "                  \"subject\": \"<email subject line>\",\n",
    "                  \"body_text\": \"<plain-text email body>\",\n",
    "                  \"body_html\": \"<HTML email body with inline styles, no external CSS>\"\n",
    "                }}\n",
    "\n",
    "                Return ONLY the JSON object. No markdown fences, no preamble.\n",
    "               \"\"\"\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Step 3 â€” Call Foundry Agent\n",
    "    # ------------------------------------------------------------\n",
    "    def _call_orchestrator(self, prompt: str) -> Dict[str, Any]:\n",
    "\n",
    "        response = self.openai_client.responses.create(\n",
    "            input=prompt,\n",
    "            extra_body={\n",
    "                \"agent\": {\n",
    "                    \"name\": self.agent_name,\n",
    "                    \"type\": \"agent_reference\",\n",
    "                }\n",
    "            },\n",
    "        )\n",
    "\n",
    "        text = self._extract_text(response)\n",
    "        parsed = json.loads(text)\n",
    "\n",
    "        self._validate_email(parsed)\n",
    "        return parsed\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Helpers\n",
    "    # ------------------------------------------------------------\n",
    "    def _extract_text(self, response) -> str:\n",
    "        for item in response.output:\n",
    "            if item.type == \"message\":\n",
    "                return item.content[0].text.strip()\n",
    "        raise RuntimeError(\"No message content returned\")\n",
    "\n",
    "    def _validate_email(self, email: Dict[str, Any]):\n",
    "\n",
    "        required = (\"subject\", \"body_text\", \"body_html\")\n",
    "\n",
    "        for key in required:\n",
    "            if key not in email:\n",
    "                raise ValueError(f\"Missing key '{key}' in agent output\")\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Public API\n",
    "    # ------------------------------------------------------------\n",
    "    def generate_email(self, imp: Dict[str, Any]) -> Dict[str, str]:\n",
    "\n",
    "        enrichment = self.get_policy_context(imp[\"policy_id\"])\n",
    "        prompt = self._build_prompt(imp, enrichment)\n",
    "        return self._call_orchestrator(prompt)\n",
    "\n",
    "# ============================================================================\n",
    "# Create email_notifications Delta table if it doesn't exist\n",
    "# ============================================================================\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS email_notifications (\n",
    "        notification_id   STRING,\n",
    "        run_id            STRING,\n",
    "        impact_id         STRING,\n",
    "        policy_id         STRING,\n",
    "        alert_id          STRING,\n",
    "        recipient_email   STRING,\n",
    "        recipient_name    STRING,\n",
    "        subject           STRING,\n",
    "        body_html         STRING,\n",
    "        body_text         STRING,\n",
    "        generation_method STRING,\n",
    "        dispatch_status   STRING,\n",
    "        dispatch_error    STRING,\n",
    "        created_at        TIMESTAMP,\n",
    "        dispatched_at     TIMESTAMP\n",
    "    ) USING DELTA\n",
    "\"\"\")\n",
    "\n",
    "print(\"âœ… email_notifications table ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000008",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“¥ Step 1 â€” Load Unnotified Impact Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000009",
   "metadata": {
    "collapsed": false,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "print(\"ğŸ“¥ Loading unnotified weather impact events from lakehouse...\")\n",
    "\n",
    "try:\n",
    "    pending_df = spark.sql(f\"\"\"\n",
    "        SELECT *\n",
    "        FROM   weather_impact_events\n",
    "        WHERE  impact_status = 'pending_notification'\n",
    "          AND  risk_score   >= {config.min_risk_score}\n",
    "        ORDER BY risk_score DESC, created_at DESC\n",
    "        LIMIT  {config.max_events_per_run}\n",
    "    \"\"\")\n",
    "    pending = [row.asDict() for row in pending_df.collect()]\n",
    "    print(f\"  Pending impact events to process: {len(pending)}\")\n",
    "except Exception as e:\n",
    "    print(f\"  âŒ Could not query weather_impact_events: {e}\")\n",
    "    print(\"     Ensure weather_alert_policy_impact.ipynb has been run first.\")\n",
    "    pending = []\n",
    "\n",
    "if not pending:\n",
    "    print(\"\\nâ„¹ï¸  No pending impact events. Either:\")\n",
    "    print(\"   â€¢ Run weather_alert_policy_impact.ipynb first to populate impact events, or\")\n",
    "    print(\"   â€¢ All current events have already been notified.\")\n",
    "\n",
    "if pending:\n",
    "    display(pending_df.select(\n",
    "        \"impact_id\", \"policy_id\", \"business_name\", \"city\", \"state\",\n",
    "        \"alert_event\", \"alert_severity\", \"risk_score\", \"contact_email\"\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000010",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ¤– Steps 2â€“3 â€” Two-Step Agent Pattern\n",
    "\n",
    "For each pending impact event, the **notebook** orchestrates two dependent calls:\n",
    "\n",
    "1. **Step 2 â€” Bootstrap Fabric Data Agent** :\n",
    "   - Configures the FabricDataAgentClient (so that it can be used by PolicyEmailOrchestrator)\n",
    "\n",
    "2. **Step 3 â€” PolicyEmailOrchestrator** :\n",
    "   PolicyEmailOrchestrator\n",
    "      â”‚\n",
    "      â”œâ”€â”€ FabricDataAgentClient  â†’ policy enrichment\n",
    "      â”‚\n",
    "      â””â”€â”€ Foundry Orchestrator Agent â†’ email generation\n",
    "\n",
    "**Why not agent-to-agent?** Fabric Data Agents currently cannot be invoked\n",
    "as a tool by another agent when the caller is a Fabric notebook session.\n",
    "This two-step pattern gives us full control and visibility at each stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000011",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Fallback: rule-based context (when Foundry is unavailable)\n",
    "# ============================================================================\n",
    "\n",
    "def _build_fallback_context(imp: Dict[str, Any]) -> str:\n",
    "    \"\"\"Build a minimal context string from the impact event data itself.\"\"\"\n",
    "    return (\n",
    "        f\"Policy {imp['policy_id']} â€” {imp['business_name']} \"\n",
    "        f\"({imp['business_type']}) in {imp['city']}, {imp['state']}. \"\n",
    "        f\"Outage threshold: {imp['threshold_minutes']} min, \"\n",
    "        f\"Hourly rate: ${imp['hourly_rate']:,.2f}, \"\n",
    "        f\"Max payout: ${imp['max_payout']:,.2f}. \"\n",
    "        f\"No additional claim history available (data agent unavailable).\"\n",
    "    )\n",
    "\n",
    "# ============================================================================\n",
    "# Fallback: rule-based email template (when Foundry is unavailable)\n",
    "# ============================================================================\n",
    "\n",
    "def generate_template_email(imp: Dict[str, Any]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Generate a professional policy impact notification email from a\n",
    "    hard-coded template. Used as fallback when Foundry is not configured.\n",
    "    \"\"\"\n",
    "    onset_str   = imp.get(\"alert_onset\").strftime(\"%B %d, %Y at %I:%M %p UTC\") if imp.get(\"alert_onset\") else \"Immediately\"\n",
    "    expires_str = imp.get(\"alert_expires\").strftime(\"%B %d, %Y at %I:%M %p UTC\") if imp.get(\"alert_expires\") else \"Until further notice\"\n",
    "\n",
    "    subject = (\n",
    "        f\"[{config.insurer_name}] Weather Alert â€” {imp['alert_event']} \"\n",
    "        f\"near {imp['city']}, {imp['state']} | Policy {imp['policy_id']}\"\n",
    "    )\n",
    "\n",
    "    body_text = textwrap.dedent(f\"\"\"\n",
    "        Dear {imp['business_name']},\n",
    "\n",
    "        This is an important notification from {config.insurer_name} regarding your\n",
    "        Business Interruption Insurance policy ({imp['policy_id']}).\n",
    "\n",
    "        A {imp['alert_severity']} weather alert has been issued in your area that\n",
    "        may impact your business operations.\n",
    "\n",
    "        ALERT DETAILS\n",
    "        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        Alert Type:   {imp['alert_event']}\n",
    "        Severity:     {imp['alert_severity']}\n",
    "        Urgency:      {imp['alert_urgency']}\n",
    "        Affected Area:{imp['alert_area_desc']}\n",
    "        Onset:        {onset_str}\n",
    "        Expires:      {expires_str}\n",
    "        Distance:     Approximately {imp['distance_km']} km from your registered location\n",
    "\n",
    "        WHAT THIS MEANS FOR YOUR POLICY\n",
    "        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        Your policy is designed to respond automatically to qualifying power\n",
    "        outages. If this weather event causes an outage that exceeds your\n",
    "        threshold of {imp['threshold_minutes']} minutes, a claim will be\n",
    "        processed automatically â€” no action is required from you.\n",
    "\n",
    "        Your coverage summary:\n",
    "          â€¢ Policy ID:          {imp['policy_id']}\n",
    "          â€¢ Outage Threshold:   {imp['threshold_minutes']} minutes\n",
    "          â€¢ Hourly Rate:        ${imp['hourly_rate']:,.2f}/hour\n",
    "          â€¢ Maximum Payout:     ${imp['max_payout']:,.2f}\n",
    "\n",
    "        RECOMMENDED STEPS\n",
    "        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        1. Review the NWS alert at https://alerts.weather.gov\n",
    "        2. Ensure your contact information is current in our portal\n",
    "        3. Document any business disruptions for your records\n",
    "        4. Claims are processed automatically â€” no claim form needed\n",
    "\n",
    "        CONTACT US\n",
    "        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        Phone:  {config.insurer_support_phone}\n",
    "        Email:  {config.insurer_support_email}\n",
    "        Portal: {config.insurer_portal_url}\n",
    "\n",
    "        This notification was generated automatically based on active NWS\n",
    "        weather alerts and your registered policy location.\n",
    "\n",
    "        Sincerely,\n",
    "        {config.insurer_name} â€” Risk Monitoring Team\n",
    "    \"\"\").strip()\n",
    "\n",
    "    body_html = (\n",
    "        \"<html><body style='font-family:Arial,sans-serif;max-width:680px;margin:auto;'>\"\n",
    "        + body_text.replace(\"\\n\", \"<br>\")\n",
    "        + \"</body></html>\"\n",
    "    )\n",
    "\n",
    "    return {\"subject\": subject, \"body_text\": body_text, \"body_html\": body_html}\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Combined: two-step agent pipeline for a single impact event\n",
    "# ============================================================================\n",
    "\n",
    "def generate_email_for_impact(imp: Dict[str, Any]) -> tuple:\n",
    "    \"\"\"\n",
    "    Two-step agent pipeline:\n",
    "      1. Fabric Data Agent (direct) â†’ enriched context\n",
    "      2. Orchestrator Agent (LLM only) â†’ email JSON\n",
    "\n",
    "    Returns (email_dict, generation_method)\n",
    "    \"\"\"\n",
    "    # Step 2: Query Fabric Data Agent for enriched context\n",
    "    if FOUNDRY_ENABLED:\n",
    "        print(f\"  ğŸ“Š Step 2 â€” Bootstrapping the PolicyEmailOrchestrator...\")\n",
    "\n",
    "        orchestrator = PolicyEmailOrchestrator(\n",
    "            foundry_endpoint=config.foundry_endpoint,\n",
    "            tenant_id=env_lib.AZURE_TENANT_ID,\n",
    "            client_id=env_lib.AZURE_CLIENT_ID,\n",
    "            client_secret=env_lib.AZURE_CLIENT_SECRET,\n",
    "            orchestrator_agent_name=env_lib.ORCHESTRATOR_AGENT,\n",
    "            insurer_config=config,\n",
    "        )\n",
    "    else:\n",
    "        enriched_context = _build_fallback_context(imp)\n",
    "\n",
    "    # Step 3: Compose email with Orchestrator Agent\n",
    "    if FOUNDRY_ENABLED and orchestrator:\n",
    "        print(f\"  âœ‰ï¸  Step 3 â€” Composing email with Orchestrator Agent...\")\n",
    "        email = orchestrator.generate_email(imp)\n",
    "        method = (\n",
    "            \"notebookâ†’Spark/SQL query (native)â†’orchestrator\"\n",
    "        )\n",
    "    else:\n",
    "        email = generate_template_email(imp)\n",
    "        method = \"rule_based_template\"\n",
    "\n",
    "    return email, method\n",
    "\n",
    "\n",
    "print(\"âœ… Email generation helpers ready.\")\n",
    "print(\"   Pattern: Notebook â†’ Spark / SQL query (native) â†’ Orchestrator Agent (LLM only)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000012",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Main loop: process each pending impact event\n",
    "# ============================================================================\n",
    "\n",
    "if not pending:\n",
    "    print(\"â„¹ï¸  No pending impact events to process. Skipping email generation.\")\n",
    "else:\n",
    "    mode_desc = (\n",
    "        \"Notebook â†’ Spark / SQL query (native) â†’ Orchestrator Agent\"\n",
    "        if FOUNDRY_ENABLED\n",
    "        else \"Rule-based template\"\n",
    "    )\n",
    "    print(f\"ğŸ¤– Processing {len(pending)} impact event(s)...\")\n",
    "    print(f\"   Using: {mode_desc}\\n\")\n",
    "\n",
    "    notification_records: List[Dict[str, Any]] = []\n",
    "\n",
    "    for i, imp in enumerate(pending, 1):\n",
    "        print(f\"[{i}/{len(pending)}] {imp['business_name']} ({imp['city']}, {imp['state']}) â€” {imp['alert_event']}\")\n",
    "\n",
    "        email, generation_method = generate_email_for_impact(imp)\n",
    "\n",
    "        notification_records.append({\n",
    "            \"notification_id\":   f\"NOTIF-{RUN_ID}-{uuid.uuid4().hex[:6].upper()}\",\n",
    "            \"run_id\":            RUN_ID,\n",
    "            \"impact_id\":         imp[\"impact_id\"],\n",
    "            \"policy_id\":         imp[\"policy_id\"],\n",
    "            \"alert_id\":          imp[\"alert_id\"],\n",
    "            \"recipient_email\":   imp[\"contact_email\"],\n",
    "            \"recipient_name\":    imp[\"business_name\"],\n",
    "            \"subject\":           email[\"subject\"],\n",
    "            \"body_html\":         email[\"body_html\"],\n",
    "            \"body_text\":         email[\"body_text\"],\n",
    "            \"generation_method\": generation_method,\n",
    "            \"dispatch_status\":   \"pending\",\n",
    "            \"dispatch_error\":    None,\n",
    "            \"created_at\":        now_utc,\n",
    "            \"dispatched_at\":     None,\n",
    "        })\n",
    "\n",
    "        # Brief pause to avoid rate-limiting on the Foundry endpoint\n",
    "        if FOUNDRY_ENABLED and i < len(pending):\n",
    "            time.sleep(1)\n",
    "\n",
    "    print(f\"\\n  âœ… Generated {len(notification_records)} email(s).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000013",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ’¾ Step 4 â€” Persist Emails to Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000014",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "if not pending:\n",
    "    print(\"â„¹ï¸  Nothing to save.\")\n",
    "else:\n",
    "    notif_schema = StructType([\n",
    "        StructField(\"notification_id\",   StringType()),\n",
    "        StructField(\"run_id\",            StringType()),\n",
    "        StructField(\"impact_id\",         StringType()),\n",
    "        StructField(\"policy_id\",         StringType()),\n",
    "        StructField(\"alert_id\",          StringType()),\n",
    "        StructField(\"recipient_email\",   StringType()),\n",
    "        StructField(\"recipient_name\",    StringType()),\n",
    "        StructField(\"subject\",           StringType()),\n",
    "        StructField(\"body_html\",         StringType()),\n",
    "        StructField(\"body_text\",         StringType()),\n",
    "        StructField(\"generation_method\", StringType()),\n",
    "        StructField(\"dispatch_status\",   StringType()),\n",
    "        StructField(\"dispatch_error\",    StringType()),\n",
    "        StructField(\"created_at\",        TimestampType()),\n",
    "        StructField(\"dispatched_at\",     TimestampType()),\n",
    "    ])\n",
    "\n",
    "    notif_df = spark.createDataFrame(notification_records, schema=notif_schema)\n",
    "    notif_df.write.format(\"delta\").mode(\"append\").saveAsTable(\"email_notifications\")\n",
    "    print(f\"âœ… Saved {len(notification_records)} email record(s) to Delta table: email_notifications\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000015",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸš€ Step 5 â€” [Optional] Dispatch Emails via Webhook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000016",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Optional: POST email payloads to a Logic App / Power Automate webhook\n",
    "# or any HTTP endpoint that accepts JSON and dispatches emails.\n",
    "#\n",
    "# Expected webhook payload shape:\n",
    "#   {\n",
    "#     \"to\":      \"recipient@example.com\",\n",
    "#     \"subject\": \"...\",\n",
    "#     \"html\":    \"<html>...\",\n",
    "#     \"text\":    \"...\",\n",
    "#     \"from\":    \"noreply@parametricshield.com\",\n",
    "#     \"metadata\": { \"notification_id\": \"...\", \"policy_id\": \"...\", \"impact_id\": \"...\" }\n",
    "#   }\n",
    "# ============================================================================\n",
    "\n",
    "if not pending:\n",
    "    print(\"â„¹ï¸  Nothing to dispatch.\")\n",
    "elif not DISPATCH_ENABLED:\n",
    "    print(\"â„¹ï¸  Email dispatch webhook not configured.\")\n",
    "    print(\"   Set config.email_dispatch_webhook to a Logic App / Power Automate URL to send emails.\")\n",
    "    print(\"   Emails are saved to the email_notifications Delta table for review.\")\n",
    "else:\n",
    "    print(f\"ğŸš€ Dispatching {len(notification_records)} email(s) via webhook...\\n\")\n",
    "    dispatched, dispatch_failed = 0, 0\n",
    "\n",
    "    for notif in notification_records:\n",
    "        payload = {\n",
    "            \"to\":      notif[\"recipient_email\"],\n",
    "            \"subject\": notif[\"subject\"],\n",
    "            \"html\":    notif[\"body_html\"],\n",
    "            \"text\":    notif[\"body_text\"],\n",
    "            \"from\":    f\"noreply@{config.insurer_support_email.split('@')[1]}\",\n",
    "            \"metadata\": {\n",
    "                \"notification_id\": notif[\"notification_id\"],\n",
    "                \"policy_id\":       notif[\"policy_id\"],\n",
    "                \"impact_id\":       notif[\"impact_id\"],\n",
    "                \"run_id\":          notif[\"run_id\"],\n",
    "            }\n",
    "        }\n",
    "        try:\n",
    "            resp = requests.post(\n",
    "                config.email_dispatch_webhook,\n",
    "                json=payload,\n",
    "                timeout=15,\n",
    "            )\n",
    "            resp.raise_for_status()\n",
    "            notif[\"dispatch_status\"] = \"dispatched\"\n",
    "            notif[\"dispatched_at\"]   = datetime.now(timezone.utc).replace(tzinfo=None)\n",
    "            dispatched += 1\n",
    "            print(f\"  âœ… Dispatched â†’ {notif['recipient_email']} ({notif['policy_id']})\")\n",
    "        except Exception as e:\n",
    "            notif[\"dispatch_status\"] = \"failed\"\n",
    "            notif[\"dispatch_error\"]  = str(e)[:500]\n",
    "            dispatch_failed += 1\n",
    "            print(f\"  âŒ Failed    â†’ {notif['recipient_email']} ({notif['policy_id']}): {e}\")\n",
    "\n",
    "    print(f\"\\n  Dispatched: {dispatched}  |  Failed: {dispatch_failed}\")\n",
    "\n",
    "    # Update dispatch status in Delta\n",
    "    if dispatched or dispatch_failed:\n",
    "        update_schema = StructType([\n",
    "            StructField(\"notification_id\", StringType()),\n",
    "            StructField(\"dispatch_status\", StringType()),\n",
    "            StructField(\"dispatch_error\",  StringType()),\n",
    "            StructField(\"dispatched_at\",   TimestampType()),\n",
    "        ])\n",
    "        update_df = spark.createDataFrame(\n",
    "            [{\"notification_id\": n[\"notification_id\"],\n",
    "              \"dispatch_status\": n[\"dispatch_status\"],\n",
    "              \"dispatch_error\":  n.get(\"dispatch_error\"),\n",
    "              \"dispatched_at\":   n.get(\"dispatched_at\")} for n in notification_records],\n",
    "            schema=update_schema,\n",
    "        )\n",
    "        update_df.createOrReplaceTempView(\"dispatch_updates\")\n",
    "        spark.sql(\"\"\"\n",
    "            MERGE INTO email_notifications AS target\n",
    "            USING dispatch_updates AS source\n",
    "            ON target.notification_id = source.notification_id\n",
    "            WHEN MATCHED THEN UPDATE SET\n",
    "                target.dispatch_status = source.dispatch_status,\n",
    "                target.dispatch_error  = source.dispatch_error,\n",
    "                target.dispatched_at   = source.dispatched_at\n",
    "        \"\"\")\n",
    "        print(\"âœ… Dispatch status updated in email_notifications.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000017",
   "metadata": {},
   "source": [
    "---\n",
    "## âœ… Step 6 â€” Mark Impact Events as Notified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000018",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "if not pending:\n",
    "    print(\"â„¹ï¸  Nothing to mark.\")\n",
    "else:\n",
    "    processed_impact_ids = [imp[\"impact_id\"] for imp in pending]\n",
    "    ids_literal = \", \".join(f\"'{iid}'\" for iid in processed_impact_ids)\n",
    "\n",
    "    try:\n",
    "        spark.sql(f\"\"\"\n",
    "            UPDATE weather_impact_events\n",
    "            SET    impact_status = 'notified'\n",
    "            WHERE  impact_id IN ({ids_literal})\n",
    "        \"\"\")\n",
    "        print(f\"âœ… Marked {len(processed_impact_ids)} impact event(s) as 'notified' in weather_impact_events.\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Could not update impact_status: {e}\")\n",
    "        print(\"   Impact events remain in 'pending_notification' status â€” they will be reprocessed next run.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000019",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“Š Step 7 â€” Summary Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000020",
   "metadata": {
    "collapsed": false,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(f\"RUN SUMMARY â€” Run ID: {RUN_ID}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "mode_label = (\n",
    "    \"Notebook â†’ Fabric Data Agent (SDK) â†’ Orchestrator Agent\"\n",
    "    if FOUNDRY_ENABLED and FABRIC_DATA_AGENT_ENABLED\n",
    "    else \"Notebook â†’ Orchestrator Agent\"\n",
    "    if FOUNDRY_ENABLED\n",
    "    else \"Rule-based template\"\n",
    ")\n",
    "print(f\"  Email generation: {mode_label}\")\n",
    "print(f\"  Impact events processed: {len(pending)}\")\n",
    "\n",
    "if pending:\n",
    "    gen_counts = {}\n",
    "    for n in notification_records:\n",
    "        m = n[\"generation_method\"]\n",
    "        gen_counts[m] = gen_counts.get(m, 0) + 1\n",
    "    for method, cnt in gen_counts.items():\n",
    "        print(f\"  Generated via {method}: {cnt}\")\n",
    "\n",
    "print()\n",
    "print(\"--- Email Notifications (This Run) ---\")\n",
    "try:\n",
    "    display(spark.sql(f\"\"\"\n",
    "        SELECT\n",
    "            notification_id,\n",
    "            policy_id,\n",
    "            recipient_name,\n",
    "            recipient_email,\n",
    "            subject,\n",
    "            generation_method,\n",
    "            dispatch_status,\n",
    "            created_at\n",
    "        FROM email_notifications\n",
    "        WHERE run_id = '{RUN_ID}'\n",
    "        ORDER BY created_at\n",
    "    \"\"\"))\n",
    "except Exception as e:\n",
    "    print(f\"  Could not display table: {e}\")\n",
    "\n",
    "print()\n",
    "print(\"--- Email Notifications (All Time) ---\")\n",
    "try:\n",
    "    display(spark.sql(\"\"\"\n",
    "        SELECT\n",
    "            generation_method,\n",
    "            dispatch_status,\n",
    "            COUNT(*) AS total,\n",
    "            MIN(created_at) AS first_sent,\n",
    "            MAX(created_at) AS last_sent\n",
    "        FROM email_notifications\n",
    "        GROUP BY generation_method, dispatch_status\n",
    "        ORDER BY total DESC\n",
    "    \"\"\"))\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print()\n",
    "print(\"--- Sample Email Preview (most recent) ---\")\n",
    "try:\n",
    "    sample = spark.sql(\"\"\"\n",
    "        SELECT subject, body_text\n",
    "        FROM   email_notifications\n",
    "        ORDER BY created_at DESC\n",
    "        LIMIT  1\n",
    "    \"\"\").collect()\n",
    "    if sample:\n",
    "        print(f\"\\nSUBJECT: {sample[0]['subject']}\\n\")\n",
    "        body_lines = (sample[0]['body_text'] or \"\").split(\"\\n\")\n",
    "        for line in body_lines[:60]:\n",
    "            print(line)\n",
    "        if len(body_lines) > 60:\n",
    "            print(f\"... [{len(body_lines) - 60} more lines]\")\n",
    "except Exception as e:\n",
    "    print(f\"  Could not preview email: {e}\")\n",
    "\n",
    "# Refresh SQL Lakehouse tables\n",
    "schema_name = \"dbo\"\n",
    "tables_df = spark.sql(f\"SHOW TABLES IN {schema_name}\")\n",
    "tables = [row.tableName for row in tables_df.collect()]\n",
    "\n",
    "for table in tables:\n",
    "    spark.sql(f\"REFRESH TABLE {schema_name}.{table}\")\n",
    "print(f\"Metadata refresh completed for schema: {schema_name}\")\n",
    "\n",
    "print()\n",
    "print(\"âœ… Notebook complete.\")\n",
    "print(\"   ğŸ“‹ Emails are stored in the email_notifications Delta table.\")\n",
    "print(\"   ğŸš€ To send emails, configure config.email_dispatch_webhook with a Logic App URL.\")"
   ]
  }
 ],
 "metadata": {
  "a365ComputeOptions": null,
  "dependencies": {
   "lakehouse": {
    "default_lakehouse": "5166d063-e222-49b7-948b-f029f463cc2b",
    "default_lakehouse_name": "parametric_insurance_lakehouse",
    "default_lakehouse_workspace_id": "c244c53e-58d3-4055-8dc8-8c79bc0ad4b0",
    "known_lakehouses": [
     {
      "id": "5166d063-e222-49b7-948b-f029f463cc2b"
     }
    ]
   }
  },
  "kernel_info": {
   "jupyter_kernel_name": null,
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "notebook_environment": {},
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "save_output": true,
  "sessionKeepAliveTimeout": 0,
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    },
    "enableDebugMode": false
   }
  },
  "synapse_widget": {
   "state": {
    "00b5c61d-4317-4bfa-b67a-2dfc46b8f7b2": {
     "persist_state": {
      "view": {
       "chartOptions": {
        "aggregationType": "sum",
        "binsNumber": 10,
        "categoryFieldKeys": [],
        "chartType": "bar",
        "isStacked": false,
        "seriesFieldKeys": [],
        "wordFrequency": "-1"
       },
       "tableOptions": {},
       "type": "details",
       "viewOptionsGroup": [
        {
         "tabItems": [
          {
           "key": "0",
           "name": "Table",
           "options": {},
           "type": "table"
          }
         ]
        }
       ]
      }
     },
     "sync_state": {
      "isSummary": false,
      "language": "scala",
      "table": {
       "rows": [
        {
         "0": "NOTIF-CEE5521E-D2DD4B",
         "1": "BI-033",
         "2": "Downtown Movie Theater",
         "3": "front.desk@dmt.com",
         "4": "Urgent Weather Update: Special Statement Affecting Downtown Movie Theater â€“ Stay Prepared",
         "5": "notebookâ†’Spark/SQL query (native)â†’orchestrator",
         "6": "pending",
         "7": "2026-02-17 02:13:58.163189"
        },
        {
         "0": "NOTIF-CEE5521E-4CA0E2",
         "1": "BI-032",
         "2": "Venice Co-Working Hub",
         "3": "manager@vch.com",
         "4": "Important Weather Alert: Special Statement Near Venice Co-Working Hub â€“ Please Review Coverage & Prepare",
         "5": "notebookâ†’Spark/SQL query (native)â†’orchestrator",
         "6": "pending",
         "7": "2026-02-17 02:13:58.163189"
        },
        {
         "0": "NOTIF-CEE5521E-0EB121",
         "1": "BI-008",
         "2": "Santa Monica Beach Cafe",
         "3": "info@beachcafe.com",
         "4": "Urgent Weather Alert: Monitoring Special Weather Statement Near Santa Monica Beach Cafe",
         "5": "notebookâ†’Spark/SQL query (native)â†’orchestrator",
         "6": "pending",
         "7": "2026-02-17 02:13:58.163189"
        },
        {
         "0": "NOTIF-CEE5521E-E10CA3",
         "1": "BI-034",
         "2": "Los Feliz Bookshop",
         "3": "manager@lfb.com",
         "4": "Special Weather Statement â€“ Important Notification for Los Feliz Bookshop",
         "5": "notebookâ†’Spark/SQL query (native)â†’orchestrator",
         "6": "pending",
         "7": "2026-02-17 02:13:58.163189"
        },
        {
         "0": "NOTIF-CEE5521E-F6505A",
         "1": "BI-030",
         "2": "Silver Lake Cold Storage Facility",
         "3": "front.desk@slc.com",
         "4": "Urgent Weather Alert: Special Statement Issued Near Silver Lake Cold Storage Facilityâ€”Please Review Your Policy Coverage and Preparations",
         "5": "notebookâ†’Spark/SQL query (native)â†’orchestrator",
         "6": "pending",
         "7": "2026-02-17 02:13:58.163189"
        },
        {
         "0": "NOTIF-CEE5521E-D0A319",
         "1": "BI-031",
         "2": "Echo Park Insurance Agency",
         "3": "contact@epi.com",
         "4": "Urgent Weather Alert: Special Statement for Echo Park Insurance Agencyâ€”Be Prepared",
         "5": "notebookâ†’Spark/SQL query (native)â†’orchestrator",
         "6": "pending",
         "7": "2026-02-17 02:13:58.163189"
        },
        {
         "0": "NOTIF-CEE5521E-60DF4B",
         "1": "BI-009",
         "2": "Hollywood Production Studio",
         "3": "production@hollywoodstudio.com",
         "4": "Urgent Weather Alert: Special Weather Statement Near Hollywood Production Studio â€“ Please Review Parametric Coverage & Preparation Steps",
         "5": "notebookâ†’Spark/SQL query (native)â†’orchestrator",
         "6": "pending",
         "7": "2026-02-17 02:13:58.163189"
        },
        {
         "0": "NOTIF-CEE5521E-83B740",
         "1": "BI-035",
         "2": "Arts District Pet Supply Store",
         "3": "owner@adp.com",
         "4": "Important Weather Update: Special Weather Statement Near Arts District Pet Supply Store",
         "5": "notebookâ†’Spark/SQL query (native)â†’orchestrator",
         "6": "pending",
         "7": "2026-02-17 02:13:58.163189"
        },
        {
         "0": "NOTIF-CEE5521E-B673C4",
         "1": "BI-008",
         "2": "Santa Monica Beach Cafe",
         "3": "info@beachcafe.com",
         "4": "Urgent: Special Weather Statement Near Santa Monica Beach Cafe â€“ Parametric Coverage Update",
         "5": "notebookâ†’Spark/SQL query (native)â†’orchestrator",
         "6": "pending",
         "7": "2026-02-17 02:13:58.163189"
        }
       ],
       "schema": [
        {
         "key": "0",
         "name": "notification_id",
         "type": "string"
        },
        {
         "key": "1",
         "name": "policy_id",
         "type": "string"
        },
        {
         "key": "2",
         "name": "recipient_name",
         "type": "string"
        },
        {
         "key": "3",
         "name": "recipient_email",
         "type": "string"
        },
        {
         "key": "4",
         "name": "subject",
         "type": "string"
        },
        {
         "key": "5",
         "name": "generation_method",
         "type": "string"
        },
        {
         "key": "6",
         "name": "dispatch_status",
         "type": "string"
        },
        {
         "key": "7",
         "name": "created_at",
         "type": "timestamp"
        }
       ],
       "truncated": false
      },
      "wranglerEntryContext": {
       "dataframeType": "pyspark"
      }
     },
     "type": "Synapse.DataFrame"
    },
    "0dbe66e4-f784-4b54-83ff-96c4b5ce6f50": {
     "persist_state": {
      "view": {
       "chartOptions": {
        "aggregationType": "sum",
        "binsNumber": 10,
        "categoryFieldKeys": [],
        "chartType": "bar",
        "isStacked": false,
        "seriesFieldKeys": [],
        "wordFrequency": "-1"
       },
       "tableOptions": {},
       "type": "details",
       "viewOptionsGroup": [
        {
         "tabItems": [
          {
           "key": "0",
           "name": "Table",
           "options": {},
           "type": "table"
          }
         ]
        }
       ]
      }
     },
     "sync_state": {
      "isSummary": false,
      "language": "scala",
      "table": {
       "rows": [
        {
         "0": "WI-BC8EFC6A-1BE69D",
         "1": "BI-008",
         "2": "Santa Monica Beach Cafe",
         "3": "Santa Monica",
         "4": "CA",
         "5": "Special Weather Statement",
         "6": "Moderate",
         "7": "0.59",
         "8": "info@beachcafe.com"
        },
        {
         "0": "WI-BC8EFC6A-0BCA6B",
         "1": "BI-009",
         "2": "Hollywood Production Studio",
         "3": "Los Angeles",
         "4": "CA",
         "5": "Special Weather Statement",
         "6": "Moderate",
         "7": "0.534",
         "8": "production@hollywoodstudio.com"
        },
        {
         "0": "WI-BC8EFC6A-A4B994",
         "1": "BI-030",
         "2": "Silver Lake Cold Storage Facility",
         "3": "Los Angeles",
         "4": "CA",
         "5": "Special Weather Statement",
         "6": "Moderate",
         "7": "0.511",
         "8": "front.desk@slc.com"
        },
        {
         "0": "WI-BC8EFC6A-EAA208",
         "1": "BI-031",
         "2": "Echo Park Insurance Agency",
         "3": "Los Angeles",
         "4": "CA",
         "5": "Special Weather Statement",
         "6": "Moderate",
         "7": "0.511",
         "8": "contact@epi.com"
        },
        {
         "0": "WI-BC8EFC6A-8C0640",
         "1": "BI-035",
         "2": "Arts District Pet Supply Store",
         "3": "Los Angeles",
         "4": "CA",
         "5": "Special Weather Statement",
         "6": "Moderate",
         "7": "0.507",
         "8": "owner@adp.com"
        },
        {
         "0": "WI-BC8EFC6A-47A4D4",
         "1": "BI-034",
         "2": "Los Feliz Bookshop",
         "3": "Los Angeles",
         "4": "CA",
         "5": "Special Weather Statement",
         "6": "Moderate",
         "7": "0.507",
         "8": "manager@lfb.com"
        },
        {
         "0": "WI-BC8EFC6A-256722",
         "1": "BI-032",
         "2": "Venice Co-Working Hub",
         "3": "Los Angeles",
         "4": "CA",
         "5": "Special Weather Statement",
         "6": "Moderate",
         "7": "0.503",
         "8": "manager@vch.com"
        },
        {
         "0": "WI-BC8EFC6A-11D1AA",
         "1": "BI-033",
         "2": "Downtown Movie Theater",
         "3": "Los Angeles",
         "4": "CA",
         "5": "Special Weather Statement",
         "6": "Moderate",
         "7": "0.499",
         "8": "front.desk@dmt.com"
        },
        {
         "0": "WI-BC8EFC6A-316D15",
         "1": "BI-008",
         "2": "Santa Monica Beach Cafe",
         "3": "Santa Monica",
         "4": "CA",
         "5": "Special Weather Statement",
         "6": "Moderate",
         "7": "0.491",
         "8": "info@beachcafe.com"
        }
       ],
       "schema": [
        {
         "key": "0",
         "name": "impact_id",
         "type": "string"
        },
        {
         "key": "1",
         "name": "policy_id",
         "type": "string"
        },
        {
         "key": "2",
         "name": "business_name",
         "type": "string"
        },
        {
         "key": "3",
         "name": "city",
         "type": "string"
        },
        {
         "key": "4",
         "name": "state",
         "type": "string"
        },
        {
         "key": "5",
         "name": "alert_event",
         "type": "string"
        },
        {
         "key": "6",
         "name": "alert_severity",
         "type": "string"
        },
        {
         "key": "7",
         "name": "risk_score",
         "type": "double"
        },
        {
         "key": "8",
         "name": "contact_email",
         "type": "string"
        }
       ],
       "truncated": false
      },
      "wranglerEntryContext": {
       "dataframeType": "pyspark"
      }
     },
     "type": "Synapse.DataFrame"
    },
    "b1ab1b4a-5872-44d7-b9c1-d52c48789671": {
     "persist_state": {
      "view": {
       "chartOptions": {
        "aggregationType": "sum",
        "binsNumber": 10,
        "categoryFieldKeys": [],
        "chartType": "bar",
        "isStacked": false,
        "seriesFieldKeys": [],
        "wordFrequency": "-1"
       },
       "tableOptions": {},
       "type": "details",
       "viewOptionsGroup": [
        {
         "tabItems": [
          {
           "key": "0",
           "name": "Table",
           "options": {},
           "type": "table"
          }
         ]
        }
       ]
      }
     },
     "sync_state": {
      "isSummary": false,
      "language": "scala",
      "table": {
       "rows": [
        {
         "0": "orchestrator+fabric_data_agent",
         "1": "pending",
         "2": "9",
         "3": "2026-02-16 18:34:55.444526",
         "4": "2026-02-16 18:34:55.444526"
        },
        {
         "0": "notebookâ†’Spark/SQL query (native)â†’orchestrator",
         "1": "pending",
         "2": "9",
         "3": "2026-02-17 02:13:58.163189",
         "4": "2026-02-17 02:13:58.163189"
        }
       ],
       "schema": [
        {
         "key": "0",
         "name": "generation_method",
         "type": "string"
        },
        {
         "key": "1",
         "name": "dispatch_status",
         "type": "string"
        },
        {
         "key": "2",
         "name": "total",
         "type": "bigint"
        },
        {
         "key": "3",
         "name": "first_sent",
         "type": "timestamp"
        },
        {
         "key": "4",
         "name": "last_sent",
         "type": "timestamp"
        }
       ],
       "truncated": false
      },
      "wranglerEntryContext": {
       "dataframeType": "pyspark"
      }
     },
     "type": "Synapse.DataFrame"
    }
   },
   "version": "0.1"
  },
  "widgets": {}
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
